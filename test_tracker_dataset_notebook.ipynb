{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install dependencies\n",
        "This code cell installs the required dependencies for the dataset processing and visualization tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WVFSGUD_hn_"
      },
      "source": [
        "## Create a Test Dataset\n",
        "\n",
        "This code cell defines a function `create_test_dataset` that creates a smaller, random subset of the main dataset for testing purposes. It randomly selects a specified number of folders from the source directory and copies them to a test directory. It also copies the model file (`.pt`) to the test directory.\n",
        "\n",
        "### Configurations:\n",
        "- `SOURCE_DIR`: The directory where the original dataset is located.\n",
        "- `TEST_DIR`: The directory where the test dataset will be created.\n",
        "- `NUM_FOLDERS_TO_SELECT`: The number of folders to randomly select from the source dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x66WM4nC_gw8",
        "outputId": "1befc927-5c1a-4e89-ea77-bf7bdab1d8b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to create test set from '/content/drive/MyDrive/Cap_Tracker_Datastet'...\n",
            "-> Creating test directory at '/content/drive/MyDrive/test_Cap_Tracker_Datastet_test'...\n",
            "-> Copying model file: best.pt\n",
            "-> Randomly selected 1 folders: 0019\n",
            "   - Copying '0019'...\n",
            "\n",
            "‚úÖ Successfully created the test dataset in '/content/drive/MyDrive/test_Cap_Tracker_Datastet_test'.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "\n",
        "# --- Configuration ---\n",
        "SOURCE_DIR = \"./Cap_Tracker_Datastet\"\n",
        "TEST_DIR = \"./test_Cap_Tracker_Datastet_test\"\n",
        "NUM_FOLDERS_TO_SELECT = 3\n",
        "\n",
        "def create_test_dataset():\n",
        "    \"\"\"\n",
        "    Creates a smaller, random subset of the main dataset for testing purposes.\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to create test set from '{SOURCE_DIR}'...\")\n",
        "\n",
        "    # 1. --- Validate Source Paths ---\n",
        "    source_dataset_path = os.path.join(SOURCE_DIR, \"dataset\")\n",
        "    if not os.path.isdir(SOURCE_DIR) or not os.path.isdir(source_dataset_path):\n",
        "        print(f\"‚ùå Error: Source directory '{SOURCE_DIR}/dataset' not found. Please run this script from the correct location.\")\n",
        "        return\n",
        "\n",
        "    # 2. --- Create Destination Directory Structure ---\n",
        "    print(f\"-> Creating test directory at '{TEST_DIR}'...\")\n",
        "    test_dataset_path = os.path.join(TEST_DIR, \"dataset\")\n",
        "    # exist_ok=True prevents an error if the directory already exists\n",
        "    os.makedirs(test_dataset_path, exist_ok=True)\n",
        "\n",
        "    # 3. --- Copy the .pt Model File ---\n",
        "    # Find the .pt file using glob, which is flexible with naming\n",
        "    pt_files = glob.glob(os.path.join(SOURCE_DIR, '*.pt'))\n",
        "    if not pt_files:\n",
        "        print(\"Ô∏èÔ∏è‚ö†Ô∏è Warning: No .pt model file found in the source directory.\")\n",
        "    else:\n",
        "        source_pt_path = pt_files[0] # Assume there's only one .pt file\n",
        "        dest_pt_path = os.path.join(TEST_DIR, os.path.basename(source_pt_path))\n",
        "        print(f\"-> Copying model file: {os.path.basename(source_pt_path)}\")\n",
        "        shutil.copy2(source_pt_path, dest_pt_path)\n",
        "\n",
        "    # 4. --- Randomly Select and Copy Dataset Folders ---\n",
        "    # Get a list of all subdirectories within the source dataset folder\n",
        "    all_subfolders = [d for d in os.listdir(source_dataset_path) if os.path.isdir(os.path.join(source_dataset_path, d))]\n",
        "\n",
        "    if len(all_subfolders) < NUM_FOLDERS_TO_SELECT:\n",
        "        print(f\"‚ùå Error: Source dataset has only {len(all_subfolders)} folders, but {NUM_FOLDERS_TO_SELECT} were requested.\")\n",
        "        return\n",
        "\n",
        "    # Randomly select a sample of folder names\n",
        "    selected_folders = random.sample(all_subfolders, NUM_FOLDERS_TO_SELECT)\n",
        "    print(f\"-> Randomly selected {NUM_FOLDERS_TO_SELECT} folders: {', '.join(selected_folders)}\")\n",
        "\n",
        "    # Copy each selected folder to the new test dataset directory\n",
        "    for folder_name in selected_folders:\n",
        "        source_folder = os.path.join(source_dataset_path, folder_name)\n",
        "        destination_folder = os.path.join(test_dataset_path, folder_name)\n",
        "\n",
        "        # Remove the destination folder if it already exists to ensure a fresh copy\n",
        "        if os.path.exists(destination_folder):\n",
        "            shutil.rmtree(destination_folder)\n",
        "\n",
        "        print(f\"   - Copying '{folder_name}'...\")\n",
        "        shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "    print(f\"\\n‚úÖ Successfully created the test dataset in '{TEST_DIR}'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_test_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code cell changes the current working directory to the test dataset directory. This is done to make it easier to work with the files in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3x60_FgF2GV",
        "outputId": "60e3e52b-2331-4115-856b-a94643c24644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/test_Cap_Tracker_Datastet_test\n"
          ]
        }
      ],
      "source": [
        "# Going to the test directory\n",
        "%cd ./test_Cap_Tracker_Datastet_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFa5d-lPDyXF"
      },
      "source": [
        "## Cleaning Dataset\n",
        "This code cell cleans the dataset by removing annotations of classes that are not in the `ALLOWED_INSTRUMENTS` list. It keeps the classes in the `ALWAYS_KEPT_CLASSES` list regardless of the `ALLOWED_INSTRUMENTS` list. The cleaned annotations are saved to a new file named `annotation_cleaned.json`.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `VIDEOS_TO_PROCESS`: A list of video folder names to process.\n",
        "- `ALLOWED_INSTRUMENTS`: A list of instrument class names to keep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWdNgvu3_6-d",
        "outputId": "5a4bd806-3df8-47a8-a6fe-0f69d4072ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Cleaning specified videos to only contain these instruments: ['Cap-Cystotome', 'Cap-Forceps', 'Forceps']\n",
            "(Note: 'Pupil, Cornea' will always be kept)\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0019/annotation_cleaned.json'\n",
            "--- Finished cleaning 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0063/annotation_cleaned.json'\n",
            "--- Finished cleaning 0063 ---\n",
            "\n",
            "üéâ All done!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚úèÔ∏è 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "# This should point to the folder containing your video subfolders.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# A list of video folder names to process.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\", \"0481\"]\n",
        "VIDEOS_TO_PROCESS = [\"0019\", \"0063\"] #<-- CHANGE THIS\n",
        "\n",
        "# A list of instrument class names that you want to KEEP.\n",
        "# \"Cannula\", \"Cap-Cystotome\", \"Cap-Forceps\", \"Cornea\", \"Forceps\",\n",
        "# \"IA-Handpiece\", \"Lens-Injector\", \"Phaco-Handpiece\", \"Primary-Knife\",\n",
        "# \"Pupil\", \"Second-Instrument\", \"Secondary-Knife\"\n",
        "# Example: ALLOWED_INSTRUMENTS = [\"Forceps\"]\n",
        "ALLOWED_INSTRUMENTS = [\"Forceps\", \"Cap-Cystotome\", \"Cap-Forceps\"] #<-- CHANGE THIS\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚öôÔ∏è 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# These classes are always preserved, regardless of the allowed instruments list.\n",
        "ALWAYS_KEPT_CLASSES = {\"Cornea\", \"Pupil\"}\n",
        "\n",
        "def clean_annotations(data, allowed_instruments):\n",
        "    \"\"\"\n",
        "    Filters the annotations list in the dataset based on a set of allowed classes.\n",
        "\n",
        "    Args:\n",
        "        data (dict): The loaded JSON data from an annotation file.\n",
        "        allowed_instruments (set): A set of instrument class names that are permitted.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the modified data (dict) and the number of removed annotations.\n",
        "    \"\"\"\n",
        "    # Combine user-specified instruments with the classes that are always kept.\n",
        "    final_allowed_classes = set(allowed_instruments).union(ALWAYS_KEPT_CLASSES)\n",
        "\n",
        "    # Create a mapping from category ID to category name for easy lookup.\n",
        "    category_id_to_name = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "\n",
        "    original_annotation_count = len(data['annotations'])\n",
        "    cleaned_annotations = []\n",
        "\n",
        "    # Iterate through each annotation instance in the file.\n",
        "    for ann in data['annotations']:\n",
        "        category_id = ann['category_id']\n",
        "        class_name = category_id_to_name.get(category_id)\n",
        "\n",
        "        # If the class name is in our final allowed list, keep the annotation.\n",
        "        if class_name in final_allowed_classes:\n",
        "            cleaned_annotations.append(ann)\n",
        "\n",
        "    # Replace the old annotations list with the new, filtered one.\n",
        "    data['annotations'] = cleaned_annotations\n",
        "    removed_count = original_annotation_count - len(cleaned_annotations)\n",
        "\n",
        "    return data, removed_count\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "def run_cleaning():\n",
        "    \"\"\"\n",
        "    Parses arguments and runs the dataset cleaning process.\n",
        "    Saves the output as a new 'annotation_cleaned.json' file.\n",
        "    \"\"\"\n",
        "    # --- Setup ---\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"‚ùå [Error] Dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        print(\"Please make sure the folder exists and you have uploaded your data.\")\n",
        "        return\n",
        "\n",
        "    allowed_instruments_set = set(ALLOWED_INSTRUMENTS)\n",
        "    print(f\"‚úÖ Cleaning specified videos to only contain these instruments: {sorted(list(allowed_instruments_set))}\")\n",
        "    print(f\"(Note: '{', '.join(ALWAYS_KEPT_CLASSES)}' will always be kept)\\n\")\n",
        "\n",
        "    # --- Processing Loop ---\n",
        "    for video_name in VIDEOS_TO_PROCESS:\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"--- Processing video: {video_name} ---\")\n",
        "\n",
        "        if not os.path.isdir(video_folder_path):\n",
        "            print(f\"  [Warning] Video folder not found: {video_folder_path}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # 1. Define file paths\n",
        "        original_annotation_path = os.path.join(video_folder_path, \"annotation.json\")\n",
        "        cleaned_annotation_path = os.path.join(video_folder_path, \"annotation_cleaned.json\")\n",
        "\n",
        "        if not os.path.exists(original_annotation_path):\n",
        "            print(f\"  [Warning] 'annotation.json' not found for {video_name}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # 2. Load the original annotation data\n",
        "        with open(original_annotation_path, 'r') as f:\n",
        "            data_to_clean = json.load(f)\n",
        "\n",
        "        # 3. Clean the annotation data\n",
        "        cleaned_data, removed_count = clean_annotations(data_to_clean, allowed_instruments_set)\n",
        "\n",
        "        if removed_count > 0:\n",
        "            print(f\"  Removed {removed_count} annotations for non-allowed instruments.\")\n",
        "        else:\n",
        "            print(\"  No non-allowed instruments found. Annotation file is already clean.\")\n",
        "\n",
        "        # 4. Save the new, cleaned data to annotation_cleaned.json\n",
        "        with open(cleaned_annotation_path, 'w') as f:\n",
        "            json.dump(cleaned_data, f, indent=4)\n",
        "        print(f\"  Saved cleaned annotations to '{cleaned_annotation_path}'\")\n",
        "\n",
        "        print(f\"--- Finished cleaning {video_name} ---\\n\")\n",
        "\n",
        "    print(\"üéâ All done!\")\n",
        "\n",
        "# --- Run the script ---\n",
        "run_cleaning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KT6epzKGdoE"
      },
      "source": [
        "## Handling Missing Labels\n",
        "This code cell handles missing labels in the dataset by using non-linear interpolation. It fills in the gaps in the annotations up to a specified maximum gap size. The interpolated annotations are saved to a new file named `annotation_miss_handled.json`.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `MAX_GAP_SIZE`: The maximum number of consecutive missing frames to interpolate.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `INPUT_ANNOTATION_FILENAME`: The filename of the input annotation file.\n",
        "- `OUTPUT_ANNOTATION_FILENAME`: The filename for the output annotation file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi65Yr8lFzFK",
        "outputId": "9cdd8a28-4bd6-477f-dd45-1e9bb2ca16da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos in 'dataset/'...\n",
            "Found 2 video(s) to process: ['0019', '0063']\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  Found gap of size 1 for annotation ID 0 from frame 409 to 409. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 1346 to 1346. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 1923 to 1923. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 1937 to 1937. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 2677 to 2678. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 223 to 223. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 409 to 409. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 471 to 472. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 587 to 587. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 595 to 596. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 620 to 620. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 623 to 624. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 628 to 628. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 631 to 631. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 669 to 672. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 679 to 680. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 683 to 683. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 685 to 685. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 694 to 695. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 713 to 714. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 722 to 725. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 730 to 733. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 742 to 743. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 746 to 746. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 757 to 757. Interpolating...\n",
            "  Found gap of size 9 for annotation ID 1 from frame 760 to 768. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 770 to 771. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 773 to 774. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 778 to 779. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 783 to 787. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 801 to 801. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 805 to 805. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 822 to 822. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 847 to 848. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 880 to 881. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 890 to 893. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 895 to 898. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 900 to 905. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 908 to 908. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 910 to 914. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 936 to 936. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 941 to 941. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 943 to 943. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 946 to 946. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 952 to 952. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 954 to 954. Interpolating...\n",
            "  Found gap of size 8 for annotation ID 1 from frame 965 to 972. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 978 to 979. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 981 to 981. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 983 to 983. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1016 to 1016. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1021 to 1022. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1029 to 1031. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1039 to 1040. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1043 to 1043. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1045 to 1045. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1052 to 1052. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1054 to 1054. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1056 to 1056. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1068 to 1068. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1089 to 1089. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1092 to 1093. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1096 to 1098. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1126 to 1126. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1142 to 1142. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1144 to 1144. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1147 to 1148. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1155 to 1155. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1173 to 1173. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1175 to 1175. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 1191 to 1196. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1198 to 1202. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 1404 to 1410. Interpolating...\n",
            "  Found gap of size 9 for annotation ID 1 from frame 1426 to 1434. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 1437 to 1440. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1443 to 1447. Interpolating...\n",
            "  Found gap of size 10 for annotation ID 1 from frame 1450 to 1459. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 1464 to 1467. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 1470 to 1473. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1480 to 1484. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1487 to 1487. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1496 to 1497. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 1499 to 1502. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 1504 to 1509. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1515 to 1516. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1522 to 1523. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1528 to 1528. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1532 to 1532. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 1534 to 1539. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1541 to 1541. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 1545 to 1550. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1553 to 1557. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 1560 to 1565. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1567 to 1568. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1596 to 1597. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1606 to 1606. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1612 to 1612. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1620 to 1622. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1624 to 1626. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1628 to 1628. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1639 to 1639. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 1652 to 1655. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1665 to 1669. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1671 to 1675. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 1691 to 1696. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1721 to 1721. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1728 to 1728. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1732 to 1733. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1738 to 1738. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1741 to 1743. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1745 to 1745. Interpolating...\n",
            "  Found gap of size 9 for annotation ID 1 from frame 1747 to 1755. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1757 to 1757. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1759 to 1759. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1776 to 1778. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 1780 to 1785. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 1820 to 1826. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1829 to 1829. Interpolating...\n",
            "  Found gap of size 8 for annotation ID 1 from frame 1834 to 1841. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1848 to 1849. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1888 to 1888. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1893 to 1893. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1897 to 1901. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1905 to 1905. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1907 to 1909. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1912 to 1912. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1914 to 1915. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1918 to 1919. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 1925 to 1931. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1933 to 1933. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1935 to 1935. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1937 to 1941. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1950 to 1951. Interpolating...\n",
            "  Found gap of size 10 for annotation ID 1 from frame 1993 to 2002. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2005 to 2006. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 2011 to 2014. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2019 to 2019. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2021 to 2021. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2024 to 2024. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2034 to 2035. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2040 to 2041. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2044 to 2045. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 2048 to 2053. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2055 to 2056. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2093 to 2094. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2102 to 2102. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 2133 to 2136. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 2148 to 2150. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2175 to 2176. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2179 to 2179. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2189 to 2189. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2200 to 2200. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 2222 to 2224. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2267 to 2267. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2271 to 2271. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2319 to 2319. Interpolating...\n",
            "  Found gap of size 8 for annotation ID 1 from frame 2321 to 2328. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2331 to 2331. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2334 to 2335. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2337 to 2338. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2340 to 2341. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2350 to 2350. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 2369 to 2374. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2381 to 2381. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2389 to 2389. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2391 to 2391. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2395 to 2395. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2397 to 2397. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2421 to 2421. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2475 to 2475. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2677 to 2677. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2818 to 2818. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 2838 to 2841. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2844 to 2844. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2851 to 2851. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2856 to 2856. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2893 to 2893. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2905 to 2905. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2965 to 2965. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2971 to 2971. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2983 to 2983. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2991 to 2991. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 2996 to 2998. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 3070 to 3070. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 3125 to 3125. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 3142 to 3143. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 32704732 from frame 409 to 409. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 32704732 from frame 2070 to 2074. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 32704732 from frame 2459 to 2459. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 32704732 from frame 2677 to 2677. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 41449297 from frame 409 to 409. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 41449297 from frame 2071 to 2074. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 41449297 from frame 2677 to 2677. Interpolating...\n",
            "Total missing labels filled: 469\n",
            "  ‚úÖ Saved new annotations to dataset/0019/annotation_miss_handled.json\n",
            "--- Finished processing 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  Found gap of size 6 for annotation ID 0 from frame 15 to 20. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 27 to 27. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 46 to 46. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 0 from frame 78 to 80. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 102 to 102. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 106 to 106. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 138 to 138. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 144 to 145. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 162 to 162. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 164 to 165. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 167 to 167. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 173 to 174. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 180 to 181. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 0 from frame 188 to 191. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 199 to 199. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 0 from frame 202 to 206. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 225 to 225. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 238 to 239. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 0 from frame 241 to 243. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 250 to 250. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 256 to 257. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 270 to 270. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 288 to 288. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 0 from frame 292 to 296. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 0 from frame 300 to 304. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 307 to 308. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 314 to 314. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 0 from frame 325 to 327. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 331 to 331. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 343 to 343. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 357 to 357. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 386 to 386. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 390 to 390. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 393 to 393. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 0 from frame 424 to 428. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 430 to 431. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 0 from frame 720 to 725. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 729 to 730. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 733 to 733. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 735 to 735. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 0 from frame 746 to 747. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 842 to 842. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 845 to 845. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 890 to 890. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 948 to 948. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 0 from frame 1174 to 1179. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 1900 to 1900. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 1904 to 1904. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 2240 to 2240. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 3150 to 3150. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 4016 to 4016. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 5289 to 5289. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 5332 to 5332. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 5335 to 5335. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 5408 to 5408. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 0 from frame 5460 to 5464. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 0 from frame 5516 to 5522. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 0 from frame 5539 to 5545. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 0 from frame 5581 to 5585. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 5695 to 5695. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 0 from frame 5701 to 5704. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 0 from frame 5721 to 5723. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 5740 to 5740. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 0 from frame 5742 to 5742. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 142 to 142. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 232 to 232. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 249 to 250. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 529 to 533. Interpolating...\n",
            "  Found gap of size 10 for annotation ID 1 from frame 612 to 621. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 623 to 624. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 979 to 983. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 988 to 988. Interpolating...\n",
            "  Found gap of size 10 for annotation ID 1 from frame 1330 to 1339. Interpolating...\n",
            "  Found gap of size 8 for annotation ID 1 from frame 1344 to 1351. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1353 to 1353. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1384 to 1384. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1386 to 1386. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1388 to 1389. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1392 to 1393. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1395 to 1396. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1426 to 1426. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1428 to 1432. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1435 to 1436. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1465 to 1465. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 1469 to 1475. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 1556 to 1559. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1561 to 1563. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1566 to 1566. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1678 to 1678. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1684 to 1686. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1698 to 1700. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1702 to 1706. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1713 to 1715. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1717 to 1718. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1721 to 1723. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 1753 to 1757. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1759 to 1761. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 1768 to 1769. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1772 to 1772. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1794 to 1794. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1801 to 1801. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1808 to 1808. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1840 to 1840. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1863 to 1863. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 1920 to 1923. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1927 to 1929. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 1934 to 1934. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 1967 to 1969. Interpolating...\n",
            "  Found gap of size 9 for annotation ID 1 from frame 2061 to 2069. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2072 to 2073. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2104 to 2104. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2120 to 2120. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2122 to 2122. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2126 to 2126. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2173 to 2173. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2175 to 2176. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2179 to 2180. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2210 to 2211. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 2283 to 2287. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 2289 to 2295. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 2304 to 2309. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2339 to 2339. Interpolating...\n",
            "  Found gap of size 10 for annotation ID 1 from frame 2354 to 2363. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 2369 to 2373. Interpolating...\n",
            "  Found gap of size 9 for annotation ID 1 from frame 2390 to 2398. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2401 to 2402. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 2440 to 2443. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2446 to 2446. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2448 to 2448. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2452 to 2452. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 2454 to 2456. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 2460 to 2462. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2464 to 2465. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 2467 to 2471. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 2503 to 2507. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2592 to 2592. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2678 to 2678. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2682 to 2682. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2684 to 2685. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 2688 to 2694. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 2708 to 2711. Interpolating...\n",
            "  Found gap of size 5 for annotation ID 1 from frame 2713 to 2717. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2719 to 2719. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2729 to 2729. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 2760 to 2763. Interpolating...\n",
            "  Found gap of size 8 for annotation ID 1 from frame 2766 to 2773. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 2830 to 2835. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 2838 to 2841. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 2891 to 2892. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2894 to 2894. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 2896 to 2896. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 2967 to 2973. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 3029 to 3030. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 3032 to 3035. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 3536 to 3537. Interpolating...\n",
            "  Found gap of size 6 for annotation ID 1 from frame 3541 to 3546. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 4872 to 4874. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 4877 to 4878. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 4881 to 4887. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 4890 to 4892. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 4899 to 4899. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 4902 to 4902. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 5035 to 5036. Interpolating...\n",
            "  Found gap of size 4 for annotation ID 1 from frame 5150 to 5153. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 5155 to 5157. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 5209 to 5209. Interpolating...\n",
            "  Found gap of size 8 for annotation ID 1 from frame 5235 to 5242. Interpolating...\n",
            "  Found gap of size 7 for annotation ID 1 from frame 5266 to 5272. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 5276 to 5277. Interpolating...\n",
            "  Found gap of size 3 for annotation ID 1 from frame 5308 to 5310. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 5312 to 5313. Interpolating...\n",
            "  Found gap of size 2 for annotation ID 1 from frame 5317 to 5318. Interpolating...\n",
            "  Found gap of size 1 for annotation ID 1 from frame 5391 to 5391. Interpolating...\n",
            "Total missing labels filled: 478\n",
            "  ‚úÖ Saved new annotations to dataset/0063/annotation_miss_handled.json\n",
            "--- Finished processing 0063 ---\n",
            "\n",
            "üéâ All done!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚úèÔ∏è 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# The maximum number of consecutive missing frames to interpolate.\n",
        "MAX_GAP_SIZE = 10\n",
        "\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE EMPTY (e.g., []) to process ALL video folders found in DATASET_ROOT.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\", \"0481\"]\n",
        "VIDEOS_TO_PROCESS = [] #<-- CHANGE THIS\n",
        "\n",
        "# The filename of the input annotation file (the one to read from).\n",
        "INPUT_ANNOTATION_FILENAME = \"annotation_cleaned.json\"\n",
        "\n",
        "# The filename for the output annotation file (the one that will be created).\n",
        "OUTPUT_ANNOTATION_FILENAME = \"annotation_miss_handled.json\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚öôÔ∏è 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def ease_in_out_sine(t):\n",
        "    \"\"\"A non-linear easing function for smoother interpolation.\"\"\"\n",
        "    return -(math.cos(math.pi * t) - 1) / 2\n",
        "\n",
        "def interpolate_bbox(bbox_start, bbox_end, t):\n",
        "    \"\"\"Interpolates bounding box [x, y, w, h] using an easing function.\"\"\"\n",
        "    t_eased = ease_in_out_sine(t)\n",
        "    return [\n",
        "        int(bbox_start[0] * (1 - t_eased) + bbox_end[0] * t_eased),\n",
        "        int(bbox_start[1] * (1 - t_eased) + bbox_end[1] * t_eased),\n",
        "        int(bbox_start[2] * (1 - t_eased) + bbox_end[2] * t_eased),\n",
        "        int(bbox_start[3] * (1 - t_eased) + bbox_end[3] * t_eased),\n",
        "    ]\n",
        "\n",
        "def interpolate_keypoints(kp_start, kp_end, t):\n",
        "    \"\"\"Interpolates keypoints [x, y, v] using an easing function.\"\"\"\n",
        "    t_eased = ease_in_out_sine(t)\n",
        "    # Only interpolate if both points are visible (v=2)\n",
        "    if kp_start[2] == 2 and kp_end[2] == 2:\n",
        "        return [\n",
        "            int(kp_start[0] * (1 - t_eased) + kp_end[0] * t_eased),\n",
        "            int(kp_start[1] * (1 - t_eased) + kp_end[1] * t_eased),\n",
        "            2 # Mark as visible\n",
        "        ]\n",
        "    return [0, 0, 0] # Return non-visible if start or end is not visible\n",
        "\n",
        "def generate_interpolated_mask(seg_start, bbox_start, bbox_interpolated):\n",
        "    \"\"\"\n",
        "    Generates a new segmentation mask by resizing a template mask.\n",
        "    \"\"\"\n",
        "    if not seg_start or not seg_start[0]:\n",
        "        return None\n",
        "\n",
        "    x_s, y_s, w_s, h_s = bbox_start\n",
        "    if w_s <= 0 or h_s <= 0: return None\n",
        "\n",
        "    template_mask = np.zeros((h_s, w_s), dtype=np.uint8)\n",
        "    poly_start = np.array(seg_start[0], dtype=np.int32).reshape((-1, 1, 2))\n",
        "    poly_start[:, :, 0] -= x_s\n",
        "    poly_start[:, :, 1] -= y_s\n",
        "    cv2.fillPoly(template_mask, [poly_start], 255)\n",
        "\n",
        "    x_i, y_i, w_i, h_i = bbox_interpolated\n",
        "    if w_i <= 0 or h_i <= 0: return None\n",
        "\n",
        "    resized_mask = cv2.resize(template_mask, (w_i, h_i), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    contours, _ = cv2.findContours(resized_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours: return None\n",
        "\n",
        "    main_contour = contours[0]\n",
        "    main_contour[:, :, 0] += x_i\n",
        "    main_contour[:, :, 1] += y_i\n",
        "\n",
        "    return [main_contour.flatten().tolist()]\n",
        "\n",
        "\n",
        "# --- Main Processing Function ---\n",
        "\n",
        "def process_annotations(data, max_gap_size):\n",
        "    \"\"\"\n",
        "    Finds and fills missing label gaps in the annotation data.\n",
        "    \"\"\"\n",
        "    total_gaps_filled = 0\n",
        "    for ann in data['annotations']:\n",
        "        num_frames = len(ann['segmentations'])\n",
        "        idx = 0\n",
        "        while idx < num_frames:\n",
        "            # Find the start of a potential gap\n",
        "            if ann['segmentations'][idx] is None and idx > 0 and ann['segmentations'][idx-1] is not None:\n",
        "                start_gap_idx = idx\n",
        "\n",
        "                # Find the end of the gap\n",
        "                end_gap_idx = -1\n",
        "                for j in range(start_gap_idx, num_frames):\n",
        "                    if ann['segmentations'][j] is not None:\n",
        "                        end_gap_idx = j\n",
        "                        break\n",
        "\n",
        "                # If a valid gap is found within the threshold, process it\n",
        "                if end_gap_idx != -1:\n",
        "                    gap_size = end_gap_idx - start_gap_idx\n",
        "                    if 0 < gap_size <= max_gap_size:\n",
        "                        print(f\"  Found gap of size {gap_size} for annotation ID {ann['id']} from frame {start_gap_idx} to {end_gap_idx-1}. Interpolating...\")\n",
        "                        total_gaps_filled += gap_size\n",
        "\n",
        "                        bbox_start = ann['bboxes'][start_gap_idx - 1]\n",
        "                        bbox_end = ann['bboxes'][end_gap_idx]\n",
        "                        seg_start = ann['segmentations'][start_gap_idx - 1]\n",
        "\n",
        "                        # Find category to determine keypoint stride\n",
        "                        category = next((cat for cat in data['categories'] if cat['id'] == ann['category_id']), None)\n",
        "                        if not category or 'keypoints' not in category: continue\n",
        "\n",
        "                        num_keypoints = len(category['keypoints'])\n",
        "                        kp_stride = num_keypoints * 3\n",
        "\n",
        "                        kp_list_start = ann['keypoints'][(start_gap_idx - 1) * kp_stride : start_gap_idx * kp_stride]\n",
        "                        kp_list_end = ann['keypoints'][end_gap_idx * kp_stride : (end_gap_idx + 1) * kp_stride]\n",
        "\n",
        "                        for i in range(gap_size):\n",
        "                            frame_idx = start_gap_idx + i\n",
        "                            t = (i + 1) / (gap_size + 1.0)\n",
        "\n",
        "                            inter_bbox = interpolate_bbox(bbox_start, bbox_end, t)\n",
        "                            ann['bboxes'][frame_idx] = inter_bbox\n",
        "\n",
        "                            inter_seg = generate_interpolated_mask(seg_start, bbox_start, inter_bbox)\n",
        "                            ann['segmentations'][frame_idx] = inter_seg\n",
        "\n",
        "                            if inter_seg and inter_seg[0]:\n",
        "                                contour = np.array(inter_seg[0]).reshape(-1, 2)\n",
        "                                ann['areas'][frame_idx] = int(cv2.contourArea(contour))\n",
        "                            else:\n",
        "                                ann['areas'][frame_idx] = 0\n",
        "\n",
        "                            inter_kp_list = []\n",
        "                            for kp_idx in range(num_keypoints):\n",
        "                                kp_start = kp_list_start[kp_idx*3 : (kp_idx+1)*3]\n",
        "                                kp_end = kp_list_end[kp_idx*3 : (kp_idx+1)*3]\n",
        "                                inter_kp = interpolate_keypoints(kp_start, kp_end, t)\n",
        "                                inter_kp_list.extend(inter_kp)\n",
        "\n",
        "                            start_kp_json_idx = frame_idx * kp_stride\n",
        "                            ann['keypoints'][start_kp_json_idx : start_kp_json_idx + kp_stride] = inter_kp_list\n",
        "\n",
        "                    idx = end_gap_idx\n",
        "                else:\n",
        "                    # No end to the gap was found, stop searching for this annotation\n",
        "                    idx = num_frames\n",
        "            else:\n",
        "                idx += 1\n",
        "\n",
        "    print(f\"Total missing labels filled: {total_gaps_filled}\")\n",
        "    return data\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚ñ∂Ô∏è 3. EXECUTION\n",
        "#    This block runs the script using the configuration above.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def run_interpolation_script():\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"‚ùå [Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    # If no specific videos are listed, find all subdirectories in the dataset folder\n",
        "    if not VIDEOS_TO_PROCESS:\n",
        "        print(f\"No specific video provided. Processing all videos in '{DATASET_ROOT}'...\")\n",
        "        video_names = [os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)]\n",
        "    else:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"‚ùå No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_names)} video(s) to process: {sorted(video_names)}\")\n",
        "\n",
        "    for video_name in sorted(video_names):\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        # Define file paths\n",
        "        input_annotation_path = os.path.join(video_folder_path, INPUT_ANNOTATION_FILENAME)\n",
        "        output_annotation_path = os.path.join(video_folder_path, OUTPUT_ANNOTATION_FILENAME)\n",
        "\n",
        "        if not os.path.exists(input_annotation_path):\n",
        "            print(f\"  [Warning] Input file '{INPUT_ANNOTATION_FILENAME}' not found for {video_name}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(input_annotation_path, 'r') as f:\n",
        "            cleaned_data = json.load(f)\n",
        "\n",
        "        # Process the data to fill gaps\n",
        "        handled_data = process_annotations(cleaned_data, MAX_GAP_SIZE)\n",
        "\n",
        "        # Save the new annotation file\n",
        "        with open(output_annotation_path, 'w') as f:\n",
        "            json.dump(handled_data, f, indent=4)\n",
        "        print(f\"  ‚úÖ Saved new annotations to {output_annotation_path}\")\n",
        "\n",
        "        print(f\"--- Finished processing {video_name} ---\")\n",
        "\n",
        "    print(\"\\nüéâ All done!\")\n",
        "\n",
        "# --- Run the script ---\n",
        "run_interpolation_script()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS6Aj8cLKHf2"
      },
      "source": [
        "## Outlier Removal\n",
        "This code cell removes outliers from the dataset. It uses a sliding window to detect outliers based on velocity and corrects them using Cubic Spline interpolation. The smoothed annotations are saved to a new file named `annotation_smooth.json`.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `WINDOW_SIZE`: The size of the sliding window used to check for local outliers.\n",
        "- `THRESHOLD_STD_DEV`: The number of standard deviations from the median velocity to consider a point an outlier.\n",
        "- `INSTRUMENT_CLASSES`: These classes are instruments whose trajectories will be smoothed.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `INPUT_ANNOTATION_FILENAME`: The filename of the input annotation file.\n",
        "- `OUTPUT_ANNOTATION_FILENAME`: The filename for the output annotation file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IuRnLgKH-dK",
        "outputId": "e4ecee68-3fe1-4f65-bef0-31df04d82072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos in 'dataset/'...\n",
            "Found 2 video(s) to process: ['0019', '0063']\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  Processing trajectory for 'Forceps' (ID: 0)...\n",
            "    -> Detected 269 outliers. Applying spline correction.\n",
            "  Processing trajectory for 'Cap-Cystotome' (ID: 1)...\n",
            "    -> Detected 243 outliers. Applying spline correction.\n",
            "  Processing trajectory for 'Cap-Forceps' (ID: 220)...\n",
            "  ‚úÖ Saved smoothed annotations to dataset/0019/annotation_smooth.json\n",
            "--- Finished smoothing for 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  Processing trajectory for 'Cap-Cystotome' (ID: 0)...\n",
            "    -> Detected 469 outliers. Applying spline correction.\n",
            "  Processing trajectory for 'Forceps' (ID: 1)...\n",
            "    -> Detected 129 outliers. Applying spline correction.\n",
            "  ‚úÖ Saved smoothed annotations to dataset/0063/annotation_smooth.json\n",
            "--- Finished smoothing for 0063 ---\n",
            "\n",
            "üéâ All done!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from collections import deque\n",
        "from scipy.interpolate import CubicSpline\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚úèÔ∏è 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# --- Smoothing Parameters ---\n",
        "# The size of the sliding window used to check for local outliers.\n",
        "WINDOW_SIZE = 30 # since the frame rate of videos is 30fps\n",
        "# The number of standard deviations from the median velocity to consider a point an outlier.\n",
        "THRESHOLD_STD_DEV = 2.0\n",
        "# These classes are instruments whose trajectories will be smoothed.\n",
        "INSTRUMENT_CLASSES = {\n",
        "    \"Cannula\", \"Cap-Cystotome\", \"Cap-Forceps\", \"Forceps\", \"IA-Handpiece\",\n",
        "    \"Lens-Injector\", \"Phaco-Handpiece\", \"Primary-Knife\", \"Second-Instrument\",\n",
        "    \"Secondary-Knife\"\n",
        "}\n",
        "\n",
        "# --- Video & File Settings ---\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE EMPTY (e.g., []) to process ALL video folders found in DATASET_ROOT.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\", \"0481\"]\n",
        "VIDEOS_TO_PROCESS = [] #<-- CHANGE THIS\n",
        "\n",
        "# The filename of the input annotation file (the one to read from).\n",
        "INPUT_ANNOTATION_FILENAME = \"annotation_miss_handled.json\"\n",
        "\n",
        "# The filename for the output annotation file (the one that will be created).\n",
        "OUTPUT_ANNOTATION_FILENAME = \"annotation_smooth.json\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚öôÔ∏è 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def smooth_trajectory_with_spline(keypoints, num_keypoints, window_size, threshold):\n",
        "    \"\"\"\n",
        "    Detects outliers in a trajectory based on velocity and corrects them\n",
        "    using Cubic Spline interpolation.\n",
        "    \"\"\"\n",
        "    # 1. Extract tip trajectory and calculate frame-to-frame velocities\n",
        "    # Assumes the 'tip' is the second keypoint in the list for a given frame.\n",
        "    tip_track, velocities = [], [0.0]\n",
        "    for i in range(0, len(keypoints), num_keypoints * 3):\n",
        "        # Tip is the second keypoint, its data starts at index 3\n",
        "        tip_data = keypoints[i+3 : i+6]\n",
        "        tip_track.append([tip_data[0], tip_data[1]] if tip_data[2] == 2 else None)\n",
        "\n",
        "    for i in range(1, len(tip_track)):\n",
        "        if tip_track[i] is not None and tip_track[i-1] is not None:\n",
        "            velocities.append(np.linalg.norm(np.array(tip_track[i]) - np.array(tip_track[i-1])))\n",
        "        else:\n",
        "            velocities.append(0.0)\n",
        "\n",
        "    # 2. Pass 1: Detect Outliers using a sliding window on velocity\n",
        "    outlier_indices = set()\n",
        "    window = deque(maxlen=window_size)\n",
        "    for i, velocity in enumerate(velocities):\n",
        "        window.append(velocity)\n",
        "        if len(window) < window_size // 2: continue\n",
        "\n",
        "        median_vel = np.median(window)\n",
        "        std_dev_vel = np.std(window)\n",
        "        # Set a minimum std deviation to handle flat-line velocity sections\n",
        "        if std_dev_vel < 1.0: std_dev_vel = 1.0\n",
        "\n",
        "        if velocity > median_vel + threshold * std_dev_vel:\n",
        "            outlier_indices.add(i)\n",
        "\n",
        "    if not outlier_indices:\n",
        "        return keypoints # No changes needed\n",
        "\n",
        "    print(f\"    -> Detected {len(outlier_indices)} outliers. Applying spline correction.\")\n",
        "\n",
        "    # 3. Pass 2: Correct Outliers with Cubic Spline Interpolation\n",
        "    good_indices, good_points = [], []\n",
        "    for i, point in enumerate(tip_track):\n",
        "        if i not in outlier_indices and point is not None:\n",
        "            good_indices.append(i)\n",
        "            good_points.append(point)\n",
        "\n",
        "    # A cubic spline needs at least 4 points for good results\n",
        "    if len(good_indices) < 4:\n",
        "        print(f\"    -> Warning: Not enough good points ({len(good_indices)}) for a reliable spline. Outliers will be removed (set to null).\")\n",
        "        for i in outlier_indices:\n",
        "            tip_track[i] = None\n",
        "    else:\n",
        "        # Create splines for x and y coordinates\n",
        "        spline_x = CubicSpline(good_indices, [p[0] for p in good_points])\n",
        "        spline_y = CubicSpline(good_indices, [p[1] for p in good_points])\n",
        "        # Use the splines to predict new positions for the outlier frames\n",
        "        for i in outlier_indices:\n",
        "            tip_track[i] = [spline_x(i), spline_y(i)]\n",
        "\n",
        "    # 4. Reconstruct the flat keypoints list with the corrected data\n",
        "    new_keypoints = list(keypoints)\n",
        "    for i, point in enumerate(tip_track):\n",
        "        idx = i * num_keypoints * 3\n",
        "        if point:\n",
        "            new_keypoints[idx + 3:idx + 6] = [int(point[0]), int(point[1]), 2]\n",
        "        else:\n",
        "            # If a point was an outlier and couldn't be interpolated, mark it as not visible\n",
        "            new_keypoints[idx + 3:idx + 6] = [0, 0, 0]\n",
        "\n",
        "    return new_keypoints\n",
        "\n",
        "def process_annotations(data, window_size, threshold):\n",
        "    \"\"\"\n",
        "    Main processing function that iterates through annotations and applies smoothing.\n",
        "    \"\"\"\n",
        "    category_map = {cat['id']: cat for cat in data['categories']}\n",
        "\n",
        "    for ann in data[\"annotations\"]:\n",
        "        class_name = category_map.get(ann['category_id'], {}).get('name')\n",
        "        if class_name in INSTRUMENT_CLASSES:\n",
        "            print(f\"  Processing trajectory for '{class_name}' (ID: {ann['id']})...\")\n",
        "            num_kps = len(category_map[ann['category_id']]['keypoints'])\n",
        "            # We need at least 2 keypoints (e.g., center and tip) to smooth the tip\n",
        "            if num_kps < 2:\n",
        "                print(f\"    -> Skipping, not enough keypoints ({num_kps}).\")\n",
        "                continue\n",
        "\n",
        "            ann['keypoints'] = smooth_trajectory_with_spline(\n",
        "                ann['keypoints'], num_kps, window_size, threshold\n",
        "            )\n",
        "    return data\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚ñ∂Ô∏è 3. EXECUTION\n",
        "#    This block runs the script using the configuration above.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def run_smoothing_script():\n",
        "    \"\"\"\n",
        "    Finds annotation files and runs the trajectory smoothing process.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"‚ùå [Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    # If no specific videos are listed, find all subdirectories\n",
        "    if not VIDEOS_TO_PROCESS:\n",
        "        print(f\"No specific video provided. Processing all videos in '{DATASET_ROOT}'...\")\n",
        "        video_names = [os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)]\n",
        "    else:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"‚ùå No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_names)} video(s) to process: {sorted(video_names)}\")\n",
        "\n",
        "    for video_name in sorted(video_names):\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        # Define file paths\n",
        "        input_path = os.path.join(video_folder_path, INPUT_ANNOTATION_FILENAME)\n",
        "        output_path = os.path.join(video_folder_path, OUTPUT_ANNOTATION_FILENAME)\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"  [Warning] Input file '{INPUT_ANNOTATION_FILENAME}' not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(input_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Run the smoothing process\n",
        "        smoothed_data = process_annotations(data, WINDOW_SIZE, THRESHOLD_STD_DEV)\n",
        "\n",
        "        # Save the new annotation file\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(smoothed_data, f, indent=4)\n",
        "        print(f\"  ‚úÖ Saved smoothed annotations to {output_path}\")\n",
        "\n",
        "        print(f\"--- Finished smoothing for {video_name} ---\")\n",
        "\n",
        "    print(\"\\nüéâ All done!\")\n",
        "\n",
        "# --- Run the script ---\n",
        "run_smoothing_script()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58KfPYygMBca"
      },
      "source": [
        "## Motion features\n",
        "This code cell adds motion features to the dataset. It calculates velocity, acceleration, and jerk for each instrument. It also calculates the relative position of the surgical instrument to the Pupil and the relative motion features. The enriched annotations are saved to a new file named `annotation_full.json`.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `INSTRUMENT_CLASSES`: These classes are instruments and will have motion features calculated.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `INPUT_ANNOTATION_FILENAME`: The filename of the input annotation file.\n",
        "- `OUTPUT_ANNOTATION_FILENAME`: The filename for the final output annotation file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtG65tjvK5iL",
        "outputId": "b5672829-7e6b-4e5e-b117-7de6cc6b19b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos in 'dataset/'...\n",
            "Found 2 video(s) to process: ['0019', '0063']\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  Calculating motion features for 'Forceps' (ID: 0).\n",
            "  Calculating motion features for 'Cap-Cystotome' (ID: 1).\n",
            "  Calculating motion features for 'Cap-Forceps' (ID: 220).\n",
            "  ‚úÖ Saved final annotations with motion features to dataset/0019/annotation_full.json\n",
            "--- Finished processing 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  Calculating motion features for 'Cap-Cystotome' (ID: 0).\n",
            "  Calculating motion features for 'Forceps' (ID: 1).\n",
            "  ‚úÖ Saved final annotations with motion features to dataset/0063/annotation_full.json\n",
            "--- Finished processing 0063 ---\n",
            "\n",
            "üéâ All done!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚úèÔ∏è 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# These classes are instruments and will have motion features calculated.\n",
        "INSTRUMENT_CLASSES = {\n",
        "    \"Cannula\", \"Cap-Cystotome\", \"Cap-Forceps\", \"Forceps\", \"IA-Handpiece\",\n",
        "    \"Lens-Injector\", \"Phaco-Handpiece\", \"Primary-Knife\", \"Second-Instrument\",\n",
        "    \"Secondary-Knife\"\n",
        "}\n",
        "\n",
        "# --- Video & File Settings ---\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE EMPTY (e.g., []) to process ALL video folders found in DATASET_ROOT.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\", \"0481\"]\n",
        "VIDEOS_TO_PROCESS = [] #<-- CHANGE THIS\n",
        "\n",
        "# The filename of the input annotation file (the one to read from).\n",
        "INPUT_ANNOTATION_FILENAME = \"annotation_smooth.json\"\n",
        "\n",
        "# The filename for the final output annotation file.\n",
        "OUTPUT_ANNOTATION_FILENAME = \"annotation_full.json\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚öôÔ∏è 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def _calculate_kinematics(position_track):\n",
        "    \"\"\"\n",
        "    Calculates velocity, acceleration, and jerk from a trajectory of 2D points.\n",
        "    \"\"\"\n",
        "    num_frames = len(position_track)\n",
        "    velocities = [None] * num_frames\n",
        "    accelerations = [None] * num_frames\n",
        "    jerks = [None] * num_frames\n",
        "\n",
        "    # Calculate Velocities (pixels/frame)\n",
        "    for i in range(1, num_frames):\n",
        "        p1 = position_track[i-1]\n",
        "        p2 = position_track[i]\n",
        "        if p1 is not None and p2 is not None:\n",
        "            velocities[i] = [p2[0] - p1[0], p2[1] - p1[1]]\n",
        "\n",
        "    # Calculate Accelerations (pixels/frame^2)\n",
        "    for i in range(1, num_frames):\n",
        "        v1 = velocities[i-1]\n",
        "        v2 = velocities[i]\n",
        "        if v1 is not None and v2 is not None:\n",
        "            accelerations[i] = [v2[0] - v1[0], v2[1] - v1[1]]\n",
        "\n",
        "    # Calculate Jerks (pixels/frame^3)\n",
        "    for i in range(1, num_frames):\n",
        "        a1 = accelerations[i-1]\n",
        "        a2 = accelerations[i]\n",
        "        if a1 is not None and a2 is not None:\n",
        "            jerks[i] = [a2[0] - a1[0], a2[1] - a1[1]]\n",
        "\n",
        "    return velocities, accelerations, jerks\n",
        "\n",
        "def process_video_annotations(data):\n",
        "    \"\"\"\n",
        "    Adds motion features to all instrument annotations in the dataset.\n",
        "    \"\"\"\n",
        "    category_map = {cat['id']: cat for cat in data['categories']}\n",
        "    if not data.get('videos') or not data['videos'][0].get('file_names'):\n",
        "        print(\"  [Error] 'videos' or 'file_names' not found in JSON. Cannot determine frame count.\")\n",
        "        return None\n",
        "    num_frames = len(data['videos'][0]['file_names'])\n",
        "\n",
        "    # 1. Find the Pupil's center trajectory first. This is our reference.\n",
        "    pupil_center_track = [None] * num_frames\n",
        "    pupil_ann = next((ann for ann in data['annotations'] if category_map.get(ann['category_id'], {}).get('name') == \"Pupil\"), None)\n",
        "\n",
        "    if pupil_ann:\n",
        "        num_keypoints = len(category_map[pupil_ann['category_id']]['keypoints'])\n",
        "        for i in range(num_frames):\n",
        "            kp_base_idx = i * num_keypoints * 3\n",
        "            # Center is the first keypoint\n",
        "            center_data = pupil_ann['keypoints'][kp_base_idx : kp_base_idx + 3]\n",
        "            if center_data[2] == 2: # If center is visible\n",
        "                pupil_center_track[i] = [center_data[0], center_data[1]]\n",
        "    else:\n",
        "        print(\"  [Warning] Pupil annotation not found. Relative kinematics will not be calculated.\")\n",
        "\n",
        "    # 2. Iterate through annotations and process instruments\n",
        "    for ann in data['annotations']:\n",
        "        class_name = category_map.get(ann['category_id'], {}).get('name')\n",
        "\n",
        "        if class_name in INSTRUMENT_CLASSES:\n",
        "            print(f\"  Calculating motion features for '{class_name}' (ID: {ann['id']}).\")\n",
        "            num_keypoints = len(category_map[ann['category_id']]['keypoints'])\n",
        "            if num_keypoints < 2:\n",
        "                print(f\"    -> Skipping, instrument requires at least 2 keypoints but has {num_keypoints}.\")\n",
        "                continue\n",
        "\n",
        "            # a. Extract the instrument's absolute tip trajectory\n",
        "            tip_track_abs = [None] * num_frames\n",
        "            for i in range(num_frames):\n",
        "                kp_base_idx = i * num_keypoints * 3\n",
        "                # Tip is the second keypoint\n",
        "                tip_data = ann['keypoints'][kp_base_idx + 3 : kp_base_idx + 6]\n",
        "                if tip_data[2] == 2: # If tip is visible\n",
        "                    tip_track_abs[i] = [tip_data[0], tip_data[1]]\n",
        "\n",
        "            # b. Calculate absolute kinematics\n",
        "            vel_abs, acc_abs, jerk_abs = _calculate_kinematics(tip_track_abs)\n",
        "\n",
        "            # c. Calculate the relative position trajectory\n",
        "            tip_track_rel = [None] * num_frames\n",
        "            for i in range(num_frames):\n",
        "                if tip_track_abs[i] is not None and pupil_center_track[i] is not None:\n",
        "                    tip_track_rel[i] = [\n",
        "                        tip_track_abs[i][0] - pupil_center_track[i][0],\n",
        "                        tip_track_abs[i][1] - pupil_center_track[i][1]\n",
        "                    ]\n",
        "\n",
        "            # d. Calculate relative kinematics\n",
        "            vel_rel, acc_rel, jerk_rel = _calculate_kinematics(tip_track_rel)\n",
        "\n",
        "            # e. Add the new \"motion_features\" object to the annotation\n",
        "            ann['motion_features'] = {\n",
        "                \"absolute\": {\n",
        "                    \"velocity\": vel_abs,\n",
        "                    \"acceleration\": acc_abs,\n",
        "                    \"jerk\": jerk_abs\n",
        "                },\n",
        "                \"relative_to_pupil\": {\n",
        "                    \"position\": tip_track_rel,\n",
        "                    \"velocity\": vel_rel,\n",
        "                    \"acceleration\": acc_rel,\n",
        "                    \"jerk\": jerk_rel\n",
        "                }\n",
        "            }\n",
        "\n",
        "    return data\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚ñ∂Ô∏è 3. EXECUTION\n",
        "#    This block runs the script using the configuration above.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def run_feature_calculation():\n",
        "    \"\"\"\n",
        "    Finds annotation files and runs the motion feature calculation process.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"‚ùå [Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    # If no specific videos are listed, find all subdirectories\n",
        "    if not VIDEOS_TO_PROCESS:\n",
        "        print(f\"No specific video provided. Processing all videos in '{DATASET_ROOT}'...\")\n",
        "        video_names = [os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)]\n",
        "    else:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"‚ùå No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_names)} video(s) to process: {sorted(video_names)}\")\n",
        "\n",
        "    # --- Processing Loop ---\n",
        "    for video_name in sorted(video_names):\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        # Define file paths\n",
        "        input_path = os.path.join(video_folder_path, INPUT_ANNOTATION_FILENAME)\n",
        "        output_path = os.path.join(video_folder_path, OUTPUT_ANNOTATION_FILENAME)\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"  [Warning] Input file '{INPUT_ANNOTATION_FILENAME}' not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(input_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Process the data to add motion features\n",
        "        enriched_data = process_video_annotations(data)\n",
        "\n",
        "        if enriched_data:\n",
        "            # Save the new, fully-featured annotation file\n",
        "            with open(output_path, 'w') as f:\n",
        "                json.dump(enriched_data, f, indent=4)\n",
        "            print(f\"  ‚úÖ Saved final annotations with motion features to {output_path}\")\n",
        "        else:\n",
        "            print(f\"  [Error] Processing failed for video {video_name}. Output file not saved.\")\n",
        "\n",
        "        print(f\"--- Finished processing {video_name} ---\")\n",
        "\n",
        "    print(\"\\nüéâ All done!\")\n",
        "\n",
        "\n",
        "# --- Run the script ---\n",
        "run_feature_calculation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwOM-eVjPKfm"
      },
      "source": [
        "## Visualize motion features and trajectories\n",
        "This code cell visualizes the motion features and trajectories. It generates and saves a grid of plots for each specified instrument. The plots include the absolute and relative trajectories, as well as the absolute and relative velocity, acceleration, and jerk.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset to visualize.\n",
        "- `VISUALIZATION_OUTPUT_DIR`: The directory where the output plot images will be saved.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `INSTRUMENTS_TO_PLOT`: A list of specific instrument names to plot. Leave empty to plot all instruments.\n",
        "- `COMPARE_WITH_CLEANED`: Set to True to overlay the original trajectory from \"annotation_cleaned.json\" for comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDplTIMtMjlr",
        "outputId": "8347480f-266f-4fe6-a558-bc1b8b39ee1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos...\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  -> Loading 'annotation_cleaned.json' for comparison.\n",
            "  -> Generating plots for 'Forceps' (ID: 0)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n",
            "     Saved plot to visualizations/0019_Forceps_motion_analysis.png\n",
            "  -> Generating plots for 'Cap-Cystotome' (ID: 1)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n",
            "     Saved plot to visualizations/0019_Cap-Cystotome_motion_analysis.png\n",
            "  -> Generating plots for 'Cap-Forceps' (ID: 220)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-20-2637010369.py:58: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  ax.legend()\n",
            "/tmp/ipython-input-20-2637010369.py:107: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  abs_ax.legend()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Saved plot to visualizations/0019_Cap-Forceps_motion_analysis.png\n",
            "--- Finished plotting for 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  -> Loading 'annotation_cleaned.json' for comparison.\n",
            "  -> Generating plots for 'Cap-Cystotome' (ID: 0)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n",
            "     Saved plot to visualizations/0063_Cap-Cystotome_motion_analysis.png\n",
            "  -> Generating plots for 'Forceps' (ID: 1)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n",
            "     Saved plot to visualizations/0063_Forceps_motion_analysis.png\n",
            "--- Finished plotting for 0063 ---\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==================================\n",
        "# === üìù GLOBAL CONFIGURATION üìù ===\n",
        "# ==================================\n",
        "# The root directory of the dataset to visualize.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# The directory where the output plot images will be saved.\n",
        "VISUALIZATION_OUTPUT_DIR = \"visualizations/\"\n",
        "\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE THIS LIST EMPTY (e.g., []) to process ALL videos.\n",
        "VIDEOS_TO_PROCESS = []\n",
        "\n",
        "# A list of specific instrument names to plot.\n",
        "# LEAVE THIS LIST EMPTY (e.g., []) to plot ALL instruments.\n",
        "INSTRUMENTS_TO_PLOT = []\n",
        "\n",
        "# Set to True to overlay the original trajectory from \"annotation_cleaned.json\"\n",
        "# for comparison. Set to False to only plot the final trajectory.\n",
        "COMPARE_WITH_CLEANED = True\n",
        "\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def calculate_magnitude(vectors):\n",
        "    \"\"\"Calculates the magnitude of a list of 2D vectors.\"\"\"\n",
        "    magnitudes = [np.linalg.norm(v) if v is not None and len(v) == 2 else np.nan for v in vectors]\n",
        "    return magnitudes\n",
        "\n",
        "def plot_kinematics(ax, data, title, color):\n",
        "    \"\"\"Plots a single kinematic feature (magnitude vs. time).\"\"\"\n",
        "    ax.plot(data, label=title, color=color, linewidth=1.5)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Frame Number\")\n",
        "    ax.set_ylabel(\"Magnitude (pixels/frame^n)\")\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    ax.legend()\n",
        "    ax.margins(x=0.01)\n",
        "\n",
        "def plot_trajectory(ax, trajectory, title, color, alpha=1.0):\n",
        "    \"\"\"Plots a 2D trajectory (Y vs. X).\"\"\"\n",
        "    valid_points = np.array([p for p in trajectory if p is not None])\n",
        "    if valid_points.size > 0:\n",
        "        ax.plot(valid_points[:, 0], valid_points[:, 1], 'o-', label=title, color=color, markersize=2, linewidth=1, alpha=alpha)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"X Coordinate\")\n",
        "    ax.set_ylabel(\"Y Coordinate\")\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "    if \"Absolute\" in title:\n",
        "        ax.invert_yaxis()\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    ax.legend()\n",
        "\n",
        "# --- Main Processing Function ---\n",
        "\n",
        "def generate_plots_for_video(data, video_name, instruments_to_plot, cleaned_data=None):\n",
        "    \"\"\"Generates and saves a grid of plots for each specified instrument.\"\"\"\n",
        "    category_map = {cat['id']: cat for cat in data['categories']}\n",
        "    cleaned_category_map = {cat['id']: cat for cat in cleaned_data['categories']} if cleaned_data else None\n",
        "\n",
        "    for ann in data['annotations']:\n",
        "        category_id = ann['category_id']\n",
        "        class_name = category_map.get(category_id, {}).get('name')\n",
        "\n",
        "        if not class_name or class_name not in instruments_to_plot:\n",
        "            continue\n",
        "\n",
        "        if 'motion_features' not in ann:\n",
        "            print(f\"  -> Skipping '{class_name}': No 'motion_features' found.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"  -> Generating plots for '{class_name}' (ID: {ann['id']})...\")\n",
        "\n",
        "        features = ann['motion_features']\n",
        "\n",
        "        # Extract the smoothed absolute trajectory\n",
        "        num_keypoints = len(category_map[category_id]['keypoints'])\n",
        "        kp_stride = num_keypoints * 3\n",
        "        absolute_trajectory = [[ann['keypoints'][i+3], ann['keypoints'][i+4]] if ann['keypoints'][i+5] == 2 else None for i in range(0, len(ann['keypoints']), kp_stride)]\n",
        "\n",
        "        # Find and extract the original trajectory for comparison\n",
        "        original_absolute_trajectory = None\n",
        "        if cleaned_data:\n",
        "            original_ann = next((o_ann for o_ann in cleaned_data['annotations'] if cleaned_category_map.get(o_ann['category_id'], {}).get('name') == class_name), None)\n",
        "            if original_ann:\n",
        "                print(f\"     Found corresponding 'cleaned' annotation for comparison.\")\n",
        "                o_num_keypoints = len(cleaned_category_map[original_ann['category_id']]['keypoints'])\n",
        "                o_kp_stride = o_num_keypoints * 3\n",
        "                original_absolute_trajectory = [[original_ann['keypoints'][i+3], original_ann['keypoints'][i+4]] if original_ann['keypoints'][i+5] == 2 else None for i in range(0, len(original_ann['keypoints']), o_kp_stride)]\n",
        "\n",
        "        # --- Create a 4x2 plot grid ---\n",
        "        fig, axes = plt.subplots(4, 2, figsize=(18, 24))\n",
        "        fig.suptitle(f\"Motion Analysis for '{class_name}'\\nVideo: {video_name}\", fontsize=20, y=0.96)\n",
        "\n",
        "        # Plotting\n",
        "        abs_ax = axes[0, 0]\n",
        "        plot_trajectory(abs_ax, absolute_trajectory, 'Smoothed Trajectory', 'royalblue')\n",
        "        if original_absolute_trajectory:\n",
        "            plot_trajectory(abs_ax, original_absolute_trajectory, 'Original (Cleaned)', 'red', alpha=0.7)\n",
        "        abs_ax.set_title(\"Absolute Trajectory Comparison\")\n",
        "        abs_ax.legend()\n",
        "\n",
        "        plot_trajectory(axes[0, 1], features['relative_to_pupil']['position'], 'Relative Trajectory (to Pupil)', 'seagreen')\n",
        "        plot_kinematics(axes[1, 0], calculate_magnitude(features['absolute']['velocity']), 'Absolute Velocity', 'royalblue')\n",
        "        plot_kinematics(axes[1, 1], calculate_magnitude(features['relative_to_pupil']['velocity']), 'Relative Velocity', 'seagreen')\n",
        "        plot_kinematics(axes[2, 0], calculate_magnitude(features['absolute']['acceleration']), 'Absolute Acceleration', 'royalblue')\n",
        "        plot_kinematics(axes[2, 1], calculate_magnitude(features['relative_to_pupil']['acceleration']), 'Relative Acceleration', 'seagreen')\n",
        "        plot_kinematics(axes[3, 0], calculate_magnitude(features['absolute']['jerk']), 'Absolute Jerk', 'royalblue')\n",
        "        plot_kinematics(axes[3, 1], calculate_magnitude(features['relative_to_pupil']['jerk']), 'Relative Jerk', 'seagreen')\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "\n",
        "        # Save the figure\n",
        "        output_filename = os.path.join(VISUALIZATION_OUTPUT_DIR, f\"{video_name}_{class_name}_motion_analysis.png\")\n",
        "        plt.savefig(output_filename, bbox_inches='tight')\n",
        "        print(f\"     Saved plot to {output_filename}\")\n",
        "        plt.close(fig)\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "\n",
        "def main():\n",
        "    os.makedirs(VISUALIZATION_OUTPUT_DIR, exist_ok=True)\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"[Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    # Determine which videos to process\n",
        "    if VIDEOS_TO_PROCESS:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "    else:\n",
        "        print(\"No specific video provided. Processing all videos...\")\n",
        "        video_names = sorted([os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)])\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    for video_name in video_names:\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        full_path = os.path.join(video_folder_path, \"annotation_full.json\")\n",
        "        if not os.path.exists(full_path):\n",
        "            print(f\"  [Warning] Input file 'annotation_full.json' not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(full_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        cleaned_data_for_comparison = None\n",
        "        if COMPARE_WITH_CLEANED:\n",
        "            cleaned_path = os.path.join(video_folder_path, \"annotation_cleaned.json\")\n",
        "            if os.path.exists(cleaned_path):\n",
        "                print(f\"  -> Loading 'annotation_cleaned.json' for comparison.\")\n",
        "                with open(cleaned_path, 'r') as f:\n",
        "                    cleaned_data_for_comparison = json.load(f)\n",
        "            else:\n",
        "                print(f\"  [Warning] Comparison file 'annotation_cleaned.json' not found. Comparison skipped.\")\n",
        "\n",
        "        # Determine which instruments to plot\n",
        "        all_instrument_names = {cat['name'] for cat in data['categories'] if cat['name'] not in {'Pupil', 'Cornea'}}\n",
        "        if INSTRUMENTS_TO_PLOT:\n",
        "            instruments_to_plot = set(INSTRUMENTS_TO_PLOT)\n",
        "        else:\n",
        "            instruments_to_plot = all_instrument_names\n",
        "\n",
        "        generate_plots_for_video(data, video_name, instruments_to_plot, cleaned_data=cleaned_data_for_comparison)\n",
        "\n",
        "        print(f\"--- Finished plotting for {video_name} ---\")\n",
        "\n",
        "# --- Run the script ---\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m42Tg3YFQQAu"
      },
      "source": [
        "## Video Visualization\n",
        "This code cell creates annotated videos from the dataset. It draws the annotations on each frame of the video and saves the annotated video to a new file.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `VIDEO_OUTPUT_DIR`: The directory where the output annotated videos will be saved.\n",
        "- `INPUT_ANNOTATION_FILENAME`: The exact name of the annotation file to use for visualization.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `COLOR_DICT`: A dictionary of colors to use for the different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmthFEbDQTnp",
        "outputId": "cc9da998-0141-4628-e739-b08de58fe11f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos...\n",
            "Found 2 video(s) to process: ['0019', '0063']\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  -> Loading annotations from: annotation_full.json\n",
            "  -> Creating video: 0019_from_annotation_full.mp4\n",
            "    Processing frame 3276/3276\n",
            "  -> ‚úÖ Successfully created video: visualized_videos_motion/0019_from_annotation_full.mp4\n",
            "--- Finished video creation for 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  -> Loading annotations from: annotation_full.json\n",
            "  -> Creating video: 0063_from_annotation_full.mp4\n",
            "    Processing frame 5799/5799\n",
            "  -> ‚úÖ Successfully created video: visualized_videos_motion/0063_from_annotation_full.mp4\n",
            "--- Finished video creation for 0063 ---\n",
            "\n",
            "üéâ All done!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚úèÔ∏è 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# Directory where the output annotated videos will be saved.\n",
        "VIDEO_OUTPUT_DIR = \"visualized_videos_motion/\"\n",
        "\n",
        "# The exact name of the annotation file to use for visualization.\n",
        "# This file must exist in each video folder you process.\n",
        "# Examples: \"annotation.json\", \"annotation_cleaned.json\", \"annotation_full.json\"\n",
        "INPUT_ANNOTATION_FILENAME = \"annotation_full.json\" #<-- CHANGE THIS\n",
        "\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE EMPTY (e.g., []) to process ALL video folders found in DATASET_ROOT.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\"]\n",
        "VIDEOS_TO_PROCESS = [] #<-- CHANGE THIS\n",
        "\n",
        "# Define a color dictionary for consistent class colors\n",
        "COLOR_DICT = {\n",
        "    \"Cannula\": (255, 0, 0), \"Cap-Cystotome\": (0, 255, 0), \"Cap-Forceps\": (0, 0, 255),\n",
        "    \"Cornea\": (255, 255, 0), \"Forceps\": (255, 0, 255), \"IA-Handpiece\": (0, 255, 255),\n",
        "    \"Lens-Injector\": (125, 125, 0), \"Phaco-Handpiece\": (0, 125, 125), \"Primary-Knife\": (125, 0, 125),\n",
        "    \"Pupil\": (50, 200, 200), \"Second-Instrument\": (200, 200, 50), \"Secondary-Knife\": (200, 50, 200),\n",
        "    \"Default\": (128, 128, 128)\n",
        "}\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚öôÔ∏è 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def draw_annotations_on_frame(frame, annotations_for_frame):\n",
        "    \"\"\"Draws all annotations for a single frame.\"\"\"\n",
        "    overlay = frame.copy()\n",
        "\n",
        "    for ann in annotations_for_frame:\n",
        "        class_name = ann['class_name']\n",
        "        color = COLOR_DICT.get(class_name, COLOR_DICT[\"Default\"])\n",
        "\n",
        "        # Draw segmentation mask with transparency\n",
        "        if ann['segmentation']:\n",
        "            poly = np.array(ann['segmentation'][0], dtype=np.int32).reshape((-1, 1, 2))\n",
        "            cv2.fillPoly(overlay, [poly], color)\n",
        "\n",
        "        # Draw bounding box\n",
        "        if ann['bbox']:\n",
        "            x, y, w, h = [int(v) for v in ann['bbox']]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "            # Draw class label\n",
        "            label = f\"{class_name}\"\n",
        "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "        # Draw keypoints (assumes max 2 keypoints: center and tip)\n",
        "        if ann['keypoints']:\n",
        "            # Center (first keypoint)\n",
        "            if ann['keypoints'][2] == 2:\n",
        "                center_x, center_y = int(ann['keypoints'][0]), int(ann['keypoints'][1])\n",
        "                cv2.circle(frame, (center_x, center_y), 6, (255, 0, 0), -1, cv2.LINE_AA) # Blue center\n",
        "            # Tip (second keypoint, if it exists)\n",
        "            if len(ann['keypoints']) > 5 and ann['keypoints'][5] == 2:\n",
        "                tip_x, tip_y = int(ann['keypoints'][3]), int(ann['keypoints'][4])\n",
        "                cv2.circle(frame, (tip_x, tip_y), 6, (0, 0, 255), -1, cv2.LINE_AA) # Red tip\n",
        "\n",
        "    # Apply the overlay with transparency\n",
        "    cv2.addWeighted(overlay, 0.4, frame, 0.6, 0, frame)\n",
        "    return frame\n",
        "\n",
        "def create_video(video_folder_path, json_filename):\n",
        "    \"\"\"Creates an annotated video from a folder of frames and a JSON file.\"\"\"\n",
        "    video_name = os.path.basename(video_folder_path)\n",
        "    input_json_path = os.path.join(video_folder_path, json_filename)\n",
        "\n",
        "    if not os.path.exists(input_json_path):\n",
        "        print(f\"  [Error] Annotation file not found: {input_json_path}. Skipping video creation.\")\n",
        "        return\n",
        "\n",
        "    print(f\"  -> Loading annotations from: {json_filename}\")\n",
        "    with open(input_json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    category_map = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    cat_id_to_num_kps = {cat['id']: len(cat.get('keypoints', [])) for cat in data['categories']}\n",
        "\n",
        "    num_frames = len(data['videos'][0]['file_names'])\n",
        "    all_frames_data = [[] for _ in range(num_frames)]\n",
        "\n",
        "    for ann in data['annotations']:\n",
        "        class_name = category_map.get(ann['category_id'], \"Unknown\")\n",
        "        num_keypoints = cat_id_to_num_kps.get(ann['category_id'], 0)\n",
        "        kp_stride = num_keypoints * 3\n",
        "\n",
        "        for i in range(num_frames):\n",
        "            # Check if the annotation exists for this frame\n",
        "            if ann.get('segmentations') and i < len(ann['segmentations']) and ann['segmentations'][i]:\n",
        "                frame_ann = {\n",
        "                    'class_name': class_name,\n",
        "                    'segmentation': ann['segmentations'][i],\n",
        "                    'bbox': ann['bboxes'][i] if ann.get('bboxes') and i < len(ann['bboxes']) else None,\n",
        "                    'keypoints': ann['keypoints'][i * kp_stride : (i + 1) * kp_stride] if ann.get('keypoints') and kp_stride > 0 else []\n",
        "                }\n",
        "                all_frames_data[i].append(frame_ann)\n",
        "\n",
        "    # --- Video Creation ---\n",
        "    output_video_name = f\"{video_name}_from_{os.path.splitext(json_filename)[0]}.mp4\"\n",
        "    output_video_path = os.path.join(VIDEO_OUTPUT_DIR, output_video_name)\n",
        "\n",
        "    width = data['videos'][0]['width']\n",
        "    height = data['videos'][0]['height']\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out_writer = cv2.VideoWriter(output_video_path, fourcc, 30.0, (width, height))\n",
        "\n",
        "    print(f\"  -> Creating video: {output_video_name}\")\n",
        "    for i, frame_filename in enumerate(data['videos'][0]['file_names']):\n",
        "        frame_path = os.path.join(video_folder_path, frame_filename)\n",
        "        if not os.path.exists(frame_path):\n",
        "            print(f\"\\n    [Warning] Frame not found: {frame_path}. Using a black frame instead.\")\n",
        "            frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            frame = cv2.imread(frame_path)\n",
        "\n",
        "        annotated_frame = draw_annotations_on_frame(frame, all_frames_data[i])\n",
        "\n",
        "        out_writer.write(annotated_frame)\n",
        "        print(f\"    Processing frame {i+1}/{num_frames}\", end='\\r')\n",
        "\n",
        "    out_writer.release()\n",
        "    print(f\"\\n  -> ‚úÖ Successfully created video: {output_video_path}\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ‚ñ∂Ô∏è 3. EXECUTION\n",
        "#    This block runs the script using the configuration above.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def run_video_creation_script():\n",
        "    \"\"\"Finds videos and their annotation files to generate annotated videos.\"\"\"\n",
        "    os.makedirs(VIDEO_OUTPUT_DIR, exist_ok=True)\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"‚ùå [Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    if not VIDEOS_TO_PROCESS:\n",
        "        print(\"No specific video provided. Processing all videos...\")\n",
        "        video_names = [os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)]\n",
        "    else:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"‚ùå No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_names)} video(s) to process: {sorted(video_names)}\")\n",
        "\n",
        "    for video_name in sorted(video_names):\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        create_video(video_folder_path, INPUT_ANNOTATION_FILENAME)\n",
        "\n",
        "        print(f\"--- Finished video creation for {video_name} ---\")\n",
        "\n",
        "    print(\"\\nüéâ All done!\")\n",
        "\n",
        "# --- Run the script ---\n",
        "run_video_creation_script()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
