{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahedmomenzadeh/tracker_dataset/blob/master/test_tracker_dataset_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Xw7unwbZYvmI",
        "outputId": "38bddfc2-f959-4474-f888-b83259829aa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkEzFkNKYpFh"
      },
      "source": [
        "## Install dependencies\n",
        "This code cell installs the required dependencies for the dataset processing and visualization tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hjpru2wYpFj"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install matplotlib\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WVFSGUD_hn_"
      },
      "source": [
        "## Create a Test Dataset\n",
        "\n",
        "This code cell defines a function `create_test_dataset` that creates a smaller, random subset of the main dataset for testing purposes. It randomly selects a specified number of folders from the source directory and copies them to a test directory. It also copies the model file (`.pt`) to the test directory.\n",
        "\n",
        "### Configurations:\n",
        "- `SOURCE_DIR`: The directory where the original dataset is located.\n",
        "- `TEST_DIR`: The directory where the test dataset will be created.\n",
        "- `NUM_FOLDERS_TO_SELECT`: The number of folders to randomly select from the source dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x66WM4nC_gw8",
        "outputId": "1befc927-5c1a-4e89-ea77-bf7bdab1d8b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to create test set from '/content/drive/MyDrive/Cap_Tracker_Datastet'...\n",
            "-> Creating test directory at '/content/drive/MyDrive/test_Cap_Tracker_Datastet_test'...\n",
            "-> Copying model file: best.pt\n",
            "-> Randomly selected 1 folders: 0019\n",
            "   - Copying '0019'...\n",
            "\n",
            "✅ Successfully created the test dataset in '/content/drive/MyDrive/test_Cap_Tracker_Datastet_test'.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import glob\n",
        "\n",
        "# --- Configuration ---\n",
        "SOURCE_DIR = \"./Cap_Tracker_Datastet\"\n",
        "TEST_DIR = \"./test_Cap_Tracker_Datastet_test\"\n",
        "NUM_FOLDERS_TO_SELECT = 3\n",
        "\n",
        "def create_test_dataset():\n",
        "    \"\"\"\n",
        "    Creates a smaller, random subset of the main dataset for testing purposes.\n",
        "    \"\"\"\n",
        "    print(f\"Attempting to create test set from '{SOURCE_DIR}'...\")\n",
        "\n",
        "    # 1. --- Validate Source Paths ---\n",
        "    source_dataset_path = os.path.join(SOURCE_DIR, \"dataset\")\n",
        "    if not os.path.isdir(SOURCE_DIR) or not os.path.isdir(source_dataset_path):\n",
        "        print(f\"❌ Error: Source directory '{SOURCE_DIR}/dataset' not found. Please run this script from the correct location.\")\n",
        "        return\n",
        "\n",
        "    # 2. --- Create Destination Directory Structure ---\n",
        "    print(f\"-> Creating test directory at '{TEST_DIR}'...\")\n",
        "    test_dataset_path = os.path.join(TEST_DIR, \"dataset\")\n",
        "    # exist_ok=True prevents an error if the directory already exists\n",
        "    os.makedirs(test_dataset_path, exist_ok=True)\n",
        "\n",
        "    # 3. --- Copy the .pt Model File ---\n",
        "    # Find the .pt file using glob, which is flexible with naming\n",
        "    pt_files = glob.glob(os.path.join(SOURCE_DIR, '*.pt'))\n",
        "    if not pt_files:\n",
        "        print(\"️️⚠️ Warning: No .pt model file found in the source directory.\")\n",
        "    else:\n",
        "        source_pt_path = pt_files[0] # Assume there's only one .pt file\n",
        "        dest_pt_path = os.path.join(TEST_DIR, os.path.basename(source_pt_path))\n",
        "        print(f\"-> Copying model file: {os.path.basename(source_pt_path)}\")\n",
        "        shutil.copy2(source_pt_path, dest_pt_path)\n",
        "\n",
        "    # 4. --- Randomly Select and Copy Dataset Folders ---\n",
        "    # Get a list of all subdirectories within the source dataset folder\n",
        "    all_subfolders = [d for d in os.listdir(source_dataset_path) if os.path.isdir(os.path.join(source_dataset_path, d))]\n",
        "\n",
        "    if len(all_subfolders) < NUM_FOLDERS_TO_SELECT:\n",
        "        print(f\"❌ Error: Source dataset has only {len(all_subfolders)} folders, but {NUM_FOLDERS_TO_SELECT} were requested.\")\n",
        "        return\n",
        "\n",
        "    # Randomly select a sample of folder names\n",
        "    selected_folders = random.sample(all_subfolders, NUM_FOLDERS_TO_SELECT)\n",
        "    print(f\"-> Randomly selected {NUM_FOLDERS_TO_SELECT} folders: {', '.join(selected_folders)}\")\n",
        "\n",
        "    # Copy each selected folder to the new test dataset directory\n",
        "    for folder_name in selected_folders:\n",
        "        source_folder = os.path.join(source_dataset_path, folder_name)\n",
        "        destination_folder = os.path.join(test_dataset_path, folder_name)\n",
        "\n",
        "        # Remove the destination folder if it already exists to ensure a fresh copy\n",
        "        if os.path.exists(destination_folder):\n",
        "            shutil.rmtree(destination_folder)\n",
        "\n",
        "        print(f\"   - Copying '{folder_name}'...\")\n",
        "        shutil.copytree(source_folder, destination_folder)\n",
        "\n",
        "    print(f\"\\n✅ Successfully created the test dataset in '{TEST_DIR}'.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_test_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2zaDp9dYpFl"
      },
      "source": [
        "This code cell changes the current working directory to the test dataset directory. This is done to make it easier to work with the files in the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3x60_FgF2GV",
        "outputId": "0eaa0a49-6f73-4a1f-9f04-1ee4ad50b913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1NfTiHHnDhGTxUHO3BoSFgdKCEW7HVMo_/Cap_Tracker_Datastet\n"
          ]
        }
      ],
      "source": [
        "# Going to the test directory\n",
        "%cd /content/drive/MyDrive/Cap_Tracker_Datastet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFa5d-lPDyXF"
      },
      "source": [
        "## Cleaning Dataset\n",
        "This code cell cleans the dataset by removing annotations of classes that are not in the `ALLOWED_INSTRUMENTS` list. It keeps the classes in the `ALWAYS_KEPT_CLASSES` list regardless of the `ALLOWED_INSTRUMENTS` list. The cleaned annotations are saved to a new file named `annotation_cleaned.json`.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `VIDEOS_TO_PROCESS`: A list of video folder names to process.\n",
        "- `ALLOWED_INSTRUMENTS`: A list of instrument class names to keep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWdNgvu3_6-d",
        "outputId": "0564703a-f8b9-4684-df35-cd7ff09132f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 No videos specified. Automatically found 177 video(s) to process.\n",
            "\n",
            "✅ Cleaning specified videos to only contain these instruments: ['Cap-Cystotome', 'Cap-Forceps', 'Forceps']\n",
            "(Note: 'Cornea, Pupil' will always be kept)\n",
            "\n",
            "--- Processing video: 0011 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0011/annotation_cleaned.json'\n",
            "--- Finished cleaning 0011 ---\n",
            "\n",
            "--- Processing video: 0134 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0134/annotation_cleaned.json'\n",
            "--- Finished cleaning 0134 ---\n",
            "\n",
            "--- Processing video: 0001 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0001/annotation_cleaned.json'\n",
            "--- Finished cleaning 0001 ---\n",
            "\n",
            "--- Processing video: 0438 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0438/annotation_cleaned.json'\n",
            "--- Finished cleaning 0438 ---\n",
            "\n",
            "--- Processing video: 0437 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0437/annotation_cleaned.json'\n",
            "--- Finished cleaning 0437 ---\n",
            "\n",
            "--- Processing video: 0420 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0420/annotation_cleaned.json'\n",
            "--- Finished cleaning 0420 ---\n",
            "\n",
            "--- Processing video: 0419 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0419/annotation_cleaned.json'\n",
            "--- Finished cleaning 0419 ---\n",
            "\n",
            "--- Processing video: 0416 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0416/annotation_cleaned.json'\n",
            "--- Finished cleaning 0416 ---\n",
            "\n",
            "--- Processing video: 0404 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0404/annotation_cleaned.json'\n",
            "--- Finished cleaning 0404 ---\n",
            "\n",
            "--- Processing video: 0412 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0412/annotation_cleaned.json'\n",
            "--- Finished cleaning 0412 ---\n",
            "\n",
            "--- Processing video: 0413 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0413/annotation_cleaned.json'\n",
            "--- Finished cleaning 0413 ---\n",
            "\n",
            "--- Processing video: 0411 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0411/annotation_cleaned.json'\n",
            "--- Finished cleaning 0411 ---\n",
            "\n",
            "--- Processing video: 0410 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0410/annotation_cleaned.json'\n",
            "--- Finished cleaning 0410 ---\n",
            "\n",
            "--- Processing video: 0408 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0408/annotation_cleaned.json'\n",
            "--- Finished cleaning 0408 ---\n",
            "\n",
            "--- Processing video: 0407 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0407/annotation_cleaned.json'\n",
            "--- Finished cleaning 0407 ---\n",
            "\n",
            "--- Processing video: 0401 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0401/annotation_cleaned.json'\n",
            "--- Finished cleaning 0401 ---\n",
            "\n",
            "--- Processing video: 0398 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0398/annotation_cleaned.json'\n",
            "--- Finished cleaning 0398 ---\n",
            "\n",
            "--- Processing video: 0399 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0399/annotation_cleaned.json'\n",
            "--- Finished cleaning 0399 ---\n",
            "\n",
            "--- Processing video: 0396 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0396/annotation_cleaned.json'\n",
            "--- Finished cleaning 0396 ---\n",
            "\n",
            "--- Processing video: 0394 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0394/annotation_cleaned.json'\n",
            "--- Finished cleaning 0394 ---\n",
            "\n",
            "--- Processing video: 0393 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0393/annotation_cleaned.json'\n",
            "--- Finished cleaning 0393 ---\n",
            "\n",
            "--- Processing video: 0390 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0390/annotation_cleaned.json'\n",
            "--- Finished cleaning 0390 ---\n",
            "\n",
            "--- Processing video: 0386 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0386/annotation_cleaned.json'\n",
            "--- Finished cleaning 0386 ---\n",
            "\n",
            "--- Processing video: 0384 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0384/annotation_cleaned.json'\n",
            "--- Finished cleaning 0384 ---\n",
            "\n",
            "--- Processing video: 0382 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0382/annotation_cleaned.json'\n",
            "--- Finished cleaning 0382 ---\n",
            "\n",
            "--- Processing video: 0351 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0351/annotation_cleaned.json'\n",
            "--- Finished cleaning 0351 ---\n",
            "\n",
            "--- Processing video: 0355 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0355/annotation_cleaned.json'\n",
            "--- Finished cleaning 0355 ---\n",
            "\n",
            "--- Processing video: 0353 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0353/annotation_cleaned.json'\n",
            "--- Finished cleaning 0353 ---\n",
            "\n",
            "--- Processing video: 0349 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0349/annotation_cleaned.json'\n",
            "--- Finished cleaning 0349 ---\n",
            "\n",
            "--- Processing video: 0346 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0346/annotation_cleaned.json'\n",
            "--- Finished cleaning 0346 ---\n",
            "\n",
            "--- Processing video: 0343 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0343/annotation_cleaned.json'\n",
            "--- Finished cleaning 0343 ---\n",
            "\n",
            "--- Processing video: 0344 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0344/annotation_cleaned.json'\n",
            "--- Finished cleaning 0344 ---\n",
            "\n",
            "--- Processing video: 0326 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0326/annotation_cleaned.json'\n",
            "--- Finished cleaning 0326 ---\n",
            "\n",
            "--- Processing video: 0342 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0342/annotation_cleaned.json'\n",
            "--- Finished cleaning 0342 ---\n",
            "\n",
            "--- Processing video: 0338 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0338/annotation_cleaned.json'\n",
            "--- Finished cleaning 0338 ---\n",
            "\n",
            "--- Processing video: 0331 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0331/annotation_cleaned.json'\n",
            "--- Finished cleaning 0331 ---\n",
            "\n",
            "--- Processing video: 0332 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0332/annotation_cleaned.json'\n",
            "--- Finished cleaning 0332 ---\n",
            "\n",
            "--- Processing video: 0330 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0330/annotation_cleaned.json'\n",
            "--- Finished cleaning 0330 ---\n",
            "\n",
            "--- Processing video: 0329 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0329/annotation_cleaned.json'\n",
            "--- Finished cleaning 0329 ---\n",
            "\n",
            "--- Processing video: 0328 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0328/annotation_cleaned.json'\n",
            "--- Finished cleaning 0328 ---\n",
            "\n",
            "--- Processing video: 0327 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0327/annotation_cleaned.json'\n",
            "--- Finished cleaning 0327 ---\n",
            "\n",
            "--- Processing video: 0321 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0321/annotation_cleaned.json'\n",
            "--- Finished cleaning 0321 ---\n",
            "\n",
            "--- Processing video: 0295 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0295/annotation_cleaned.json'\n",
            "--- Finished cleaning 0295 ---\n",
            "\n",
            "--- Processing video: 0233 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0233/annotation_cleaned.json'\n",
            "--- Finished cleaning 0233 ---\n",
            "\n",
            "--- Processing video: 0223 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0223/annotation_cleaned.json'\n",
            "--- Finished cleaning 0223 ---\n",
            "\n",
            "--- Processing video: 0222 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0222/annotation_cleaned.json'\n",
            "--- Finished cleaning 0222 ---\n",
            "\n",
            "--- Processing video: 0221 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0221/annotation_cleaned.json'\n",
            "--- Finished cleaning 0221 ---\n",
            "\n",
            "--- Processing video: 0220 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0220/annotation_cleaned.json'\n",
            "--- Finished cleaning 0220 ---\n",
            "\n",
            "--- Processing video: 0211 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0211/annotation_cleaned.json'\n",
            "--- Finished cleaning 0211 ---\n",
            "\n",
            "--- Processing video: 0209 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0209/annotation_cleaned.json'\n",
            "--- Finished cleaning 0209 ---\n",
            "\n",
            "--- Processing video: 0208 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0208/annotation_cleaned.json'\n",
            "--- Finished cleaning 0208 ---\n",
            "\n",
            "--- Processing video: 0204 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0204/annotation_cleaned.json'\n",
            "--- Finished cleaning 0204 ---\n",
            "\n",
            "--- Processing video: 0202 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0202/annotation_cleaned.json'\n",
            "--- Finished cleaning 0202 ---\n",
            "\n",
            "--- Processing video: 0192 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0192/annotation_cleaned.json'\n",
            "--- Finished cleaning 0192 ---\n",
            "\n",
            "--- Processing video: 0190 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0190/annotation_cleaned.json'\n",
            "--- Finished cleaning 0190 ---\n",
            "\n",
            "--- Processing video: 0181 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0181/annotation_cleaned.json'\n",
            "--- Finished cleaning 0181 ---\n",
            "\n",
            "--- Processing video: 0125 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0125/annotation_cleaned.json'\n",
            "--- Finished cleaning 0125 ---\n",
            "\n",
            "--- Processing video: 0107 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0107/annotation_cleaned.json'\n",
            "--- Finished cleaning 0107 ---\n",
            "\n",
            "--- Processing video: 0101 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0101/annotation_cleaned.json'\n",
            "--- Finished cleaning 0101 ---\n",
            "\n",
            "--- Processing video: 0082 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0082/annotation_cleaned.json'\n",
            "--- Finished cleaning 0082 ---\n",
            "\n",
            "--- Processing video: 0068 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0068/annotation_cleaned.json'\n",
            "--- Finished cleaning 0068 ---\n",
            "\n",
            "--- Processing video: 0065 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0065/annotation_cleaned.json'\n",
            "--- Finished cleaning 0065 ---\n",
            "\n",
            "--- Processing video: 0066 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0066/annotation_cleaned.json'\n",
            "--- Finished cleaning 0066 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0063/annotation_cleaned.json'\n",
            "--- Finished cleaning 0063 ---\n",
            "\n",
            "--- Processing video: 0062 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0062/annotation_cleaned.json'\n",
            "--- Finished cleaning 0062 ---\n",
            "\n",
            "--- Processing video: 0060 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0060/annotation_cleaned.json'\n",
            "--- Finished cleaning 0060 ---\n",
            "\n",
            "--- Processing video: 0059 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0059/annotation_cleaned.json'\n",
            "--- Finished cleaning 0059 ---\n",
            "\n",
            "--- Processing video: 0053 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0053/annotation_cleaned.json'\n",
            "--- Finished cleaning 0053 ---\n",
            "\n",
            "--- Processing video: 0051 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0051/annotation_cleaned.json'\n",
            "--- Finished cleaning 0051 ---\n",
            "\n",
            "--- Processing video: 0049 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0049/annotation_cleaned.json'\n",
            "--- Finished cleaning 0049 ---\n",
            "\n",
            "--- Processing video: 0046 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0046/annotation_cleaned.json'\n",
            "--- Finished cleaning 0046 ---\n",
            "\n",
            "--- Processing video: 0039 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0039/annotation_cleaned.json'\n",
            "--- Finished cleaning 0039 ---\n",
            "\n",
            "--- Processing video: 0037 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0037/annotation_cleaned.json'\n",
            "--- Finished cleaning 0037 ---\n",
            "\n",
            "--- Processing video: 0038 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0038/annotation_cleaned.json'\n",
            "--- Finished cleaning 0038 ---\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0019/annotation_cleaned.json'\n",
            "--- Finished cleaning 0019 ---\n",
            "\n",
            "--- Processing video: 0017 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0017/annotation_cleaned.json'\n",
            "--- Finished cleaning 0017 ---\n",
            "\n",
            "--- Processing video: 0012 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0012/annotation_cleaned.json'\n",
            "--- Finished cleaning 0012 ---\n",
            "\n",
            "--- Processing video: 0006 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0006/annotation_cleaned.json'\n",
            "--- Finished cleaning 0006 ---\n",
            "\n",
            "--- Processing video: 0118 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0118/annotation_cleaned.json'\n",
            "--- Finished cleaning 0118 ---\n",
            "\n",
            "--- Processing video: 0780 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0780/annotation_cleaned.json'\n",
            "--- Finished cleaning 0780 ---\n",
            "\n",
            "--- Processing video: 0747 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0747/annotation_cleaned.json'\n",
            "--- Finished cleaning 0747 ---\n",
            "\n",
            "--- Processing video: 0724 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0724/annotation_cleaned.json'\n",
            "--- Finished cleaning 0724 ---\n",
            "\n",
            "--- Processing video: 0721 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0721/annotation_cleaned.json'\n",
            "--- Finished cleaning 0721 ---\n",
            "\n",
            "--- Processing video: 0716 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0716/annotation_cleaned.json'\n",
            "--- Finished cleaning 0716 ---\n",
            "\n",
            "--- Processing video: 0713 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0713/annotation_cleaned.json'\n",
            "--- Finished cleaning 0713 ---\n",
            "\n",
            "--- Processing video: 0711 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0711/annotation_cleaned.json'\n",
            "--- Finished cleaning 0711 ---\n",
            "\n",
            "--- Processing video: 0674 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0674/annotation_cleaned.json'\n",
            "--- Finished cleaning 0674 ---\n",
            "\n",
            "--- Processing video: 0669 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0669/annotation_cleaned.json'\n",
            "--- Finished cleaning 0669 ---\n",
            "\n",
            "--- Processing video: 0642 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0642/annotation_cleaned.json'\n",
            "--- Finished cleaning 0642 ---\n",
            "\n",
            "--- Processing video: 0640 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0640/annotation_cleaned.json'\n",
            "--- Finished cleaning 0640 ---\n",
            "\n",
            "--- Processing video: 0610 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0610/annotation_cleaned.json'\n",
            "--- Finished cleaning 0610 ---\n",
            "\n",
            "--- Processing video: 0605 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0605/annotation_cleaned.json'\n",
            "--- Finished cleaning 0605 ---\n",
            "\n",
            "--- Processing video: 0598 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0598/annotation_cleaned.json'\n",
            "--- Finished cleaning 0598 ---\n",
            "\n",
            "--- Processing video: 0560 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0560/annotation_cleaned.json'\n",
            "--- Finished cleaning 0560 ---\n",
            "\n",
            "--- Processing video: 0549 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0549/annotation_cleaned.json'\n",
            "--- Finished cleaning 0549 ---\n",
            "\n",
            "--- Processing video: 0538 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0538/annotation_cleaned.json'\n",
            "--- Finished cleaning 0538 ---\n",
            "\n",
            "--- Processing video: 0534 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0534/annotation_cleaned.json'\n",
            "--- Finished cleaning 0534 ---\n",
            "\n",
            "--- Processing video: 0533 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0533/annotation_cleaned.json'\n",
            "--- Finished cleaning 0533 ---\n",
            "\n",
            "--- Processing video: 0505 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0505/annotation_cleaned.json'\n",
            "--- Finished cleaning 0505 ---\n",
            "\n",
            "--- Processing video: 0495 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0495/annotation_cleaned.json'\n",
            "--- Finished cleaning 0495 ---\n",
            "\n",
            "--- Processing video: 0481 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0481/annotation_cleaned.json'\n",
            "--- Finished cleaning 0481 ---\n",
            "\n",
            "--- Processing video: 0476 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0476/annotation_cleaned.json'\n",
            "--- Finished cleaning 0476 ---\n",
            "\n",
            "--- Processing video: 0474 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0474/annotation_cleaned.json'\n",
            "--- Finished cleaning 0474 ---\n",
            "\n",
            "--- Processing video: 0472 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0472/annotation_cleaned.json'\n",
            "--- Finished cleaning 0472 ---\n",
            "\n",
            "--- Processing video: 0470 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0470/annotation_cleaned.json'\n",
            "--- Finished cleaning 0470 ---\n",
            "\n",
            "--- Processing video: 0453 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0453/annotation_cleaned.json'\n",
            "--- Finished cleaning 0453 ---\n",
            "\n",
            "--- Processing video: 0439 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0439/annotation_cleaned.json'\n",
            "--- Finished cleaning 0439 ---\n",
            "\n",
            "--- Processing video: 0429 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0429/annotation_cleaned.json'\n",
            "--- Finished cleaning 0429 ---\n",
            "\n",
            "--- Processing video: 0426 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0426/annotation_cleaned.json'\n",
            "--- Finished cleaning 0426 ---\n",
            "\n",
            "--- Processing video: 0425 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0425/annotation_cleaned.json'\n",
            "--- Finished cleaning 0425 ---\n",
            "\n",
            "--- Processing video: 0423 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0423/annotation_cleaned.json'\n",
            "--- Finished cleaning 0423 ---\n",
            "\n",
            "--- Processing video: 0380 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0380/annotation_cleaned.json'\n",
            "--- Finished cleaning 0380 ---\n",
            "\n",
            "--- Processing video: 0378 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0378/annotation_cleaned.json'\n",
            "--- Finished cleaning 0378 ---\n",
            "\n",
            "--- Processing video: 0377 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0377/annotation_cleaned.json'\n",
            "--- Finished cleaning 0377 ---\n",
            "\n",
            "--- Processing video: 0369 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0369/annotation_cleaned.json'\n",
            "--- Finished cleaning 0369 ---\n",
            "\n",
            "--- Processing video: 0365 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0365/annotation_cleaned.json'\n",
            "--- Finished cleaning 0365 ---\n",
            "\n",
            "--- Processing video: 0320 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0320/annotation_cleaned.json'\n",
            "--- Finished cleaning 0320 ---\n",
            "\n",
            "--- Processing video: 0313 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0313/annotation_cleaned.json'\n",
            "--- Finished cleaning 0313 ---\n",
            "\n",
            "--- Processing video: 0314 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0314/annotation_cleaned.json'\n",
            "--- Finished cleaning 0314 ---\n",
            "\n",
            "--- Processing video: 0303 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0303/annotation_cleaned.json'\n",
            "--- Finished cleaning 0303 ---\n",
            "\n",
            "--- Processing video: 0289 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0289/annotation_cleaned.json'\n",
            "--- Finished cleaning 0289 ---\n",
            "\n",
            "--- Processing video: 0185 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0185/annotation_cleaned.json'\n",
            "--- Finished cleaning 0185 ---\n",
            "\n",
            "--- Processing video: 0168 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0168/annotation_cleaned.json'\n",
            "--- Finished cleaning 0168 ---\n",
            "\n",
            "--- Processing video: 0151 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0151/annotation_cleaned.json'\n",
            "--- Finished cleaning 0151 ---\n",
            "\n",
            "--- Processing video: 0154 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0154/annotation_cleaned.json'\n",
            "--- Finished cleaning 0154 ---\n",
            "\n",
            "--- Processing video: 0139 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0139/annotation_cleaned.json'\n",
            "--- Finished cleaning 0139 ---\n",
            "\n",
            "--- Processing video: 0099 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0099/annotation_cleaned.json'\n",
            "--- Finished cleaning 0099 ---\n",
            "\n",
            "--- Processing video: 0073 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0073/annotation_cleaned.json'\n",
            "--- Finished cleaning 0073 ---\n",
            "\n",
            "--- Processing video: 0045 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0045/annotation_cleaned.json'\n",
            "--- Finished cleaning 0045 ---\n",
            "\n",
            "--- Processing video: 0020 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0020/annotation_cleaned.json'\n",
            "--- Finished cleaning 0020 ---\n",
            "\n",
            "--- Processing video: 0005 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0005/annotation_cleaned.json'\n",
            "--- Finished cleaning 0005 ---\n",
            "\n",
            "--- Processing video: 0003 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0003/annotation_cleaned.json'\n",
            "--- Finished cleaning 0003 ---\n",
            "\n",
            "--- Processing video: 0028 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0028/annotation_cleaned.json'\n",
            "--- Finished cleaning 0028 ---\n",
            "\n",
            "--- Processing video: 0064 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0064/annotation_cleaned.json'\n",
            "--- Finished cleaning 0064 ---\n",
            "\n",
            "--- Processing video: 0061 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0061/annotation_cleaned.json'\n",
            "--- Finished cleaning 0061 ---\n",
            "\n",
            "--- Processing video: 0058 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0058/annotation_cleaned.json'\n",
            "--- Finished cleaning 0058 ---\n",
            "\n",
            "--- Processing video: 0057 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0057/annotation_cleaned.json'\n",
            "--- Finished cleaning 0057 ---\n",
            "\n",
            "--- Processing video: 0056 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0056/annotation_cleaned.json'\n",
            "--- Finished cleaning 0056 ---\n",
            "\n",
            "--- Processing video: 0055 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0055/annotation_cleaned.json'\n",
            "--- Finished cleaning 0055 ---\n",
            "\n",
            "--- Processing video: 0054 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0054/annotation_cleaned.json'\n",
            "--- Finished cleaning 0054 ---\n",
            "\n",
            "--- Processing video: 0050 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0050/annotation_cleaned.json'\n",
            "--- Finished cleaning 0050 ---\n",
            "\n",
            "--- Processing video: 0048 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0048/annotation_cleaned.json'\n",
            "--- Finished cleaning 0048 ---\n",
            "\n",
            "--- Processing video: 0047 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0047/annotation_cleaned.json'\n",
            "--- Finished cleaning 0047 ---\n",
            "\n",
            "--- Processing video: 0044 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0044/annotation_cleaned.json'\n",
            "--- Finished cleaning 0044 ---\n",
            "\n",
            "--- Processing video: 0043 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0043/annotation_cleaned.json'\n",
            "--- Finished cleaning 0043 ---\n",
            "\n",
            "--- Processing video: 0042 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0042/annotation_cleaned.json'\n",
            "--- Finished cleaning 0042 ---\n",
            "\n",
            "--- Processing video: 0041 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0041/annotation_cleaned.json'\n",
            "--- Finished cleaning 0041 ---\n",
            "\n",
            "--- Processing video: 0040 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0040/annotation_cleaned.json'\n",
            "--- Finished cleaning 0040 ---\n",
            "\n",
            "--- Processing video: 0036 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0036/annotation_cleaned.json'\n",
            "--- Finished cleaning 0036 ---\n",
            "\n",
            "--- Processing video: 0035 ---\n",
            "  Removed 3 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0035/annotation_cleaned.json'\n",
            "--- Finished cleaning 0035 ---\n",
            "\n",
            "--- Processing video: 0034 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0034/annotation_cleaned.json'\n",
            "--- Finished cleaning 0034 ---\n",
            "\n",
            "--- Processing video: 0033 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0033/annotation_cleaned.json'\n",
            "--- Finished cleaning 0033 ---\n",
            "\n",
            "--- Processing video: 0032 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0032/annotation_cleaned.json'\n",
            "--- Finished cleaning 0032 ---\n",
            "\n",
            "--- Processing video: 0031 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0031/annotation_cleaned.json'\n",
            "--- Finished cleaning 0031 ---\n",
            "\n",
            "--- Processing video: 0030 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0030/annotation_cleaned.json'\n",
            "--- Finished cleaning 0030 ---\n",
            "\n",
            "--- Processing video: 0029 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0029/annotation_cleaned.json'\n",
            "--- Finished cleaning 0029 ---\n",
            "\n",
            "--- Processing video: 0026 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0026/annotation_cleaned.json'\n",
            "--- Finished cleaning 0026 ---\n",
            "\n",
            "--- Processing video: 0025 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0025/annotation_cleaned.json'\n",
            "--- Finished cleaning 0025 ---\n",
            "\n",
            "--- Processing video: 0024 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0024/annotation_cleaned.json'\n",
            "--- Finished cleaning 0024 ---\n",
            "\n",
            "--- Processing video: 0023 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0023/annotation_cleaned.json'\n",
            "--- Finished cleaning 0023 ---\n",
            "\n",
            "--- Processing video: 0022 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0022/annotation_cleaned.json'\n",
            "--- Finished cleaning 0022 ---\n",
            "\n",
            "--- Processing video: 0021 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0021/annotation_cleaned.json'\n",
            "--- Finished cleaning 0021 ---\n",
            "\n",
            "--- Processing video: 0018 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0018/annotation_cleaned.json'\n",
            "--- Finished cleaning 0018 ---\n",
            "\n",
            "--- Processing video: 0016 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0016/annotation_cleaned.json'\n",
            "--- Finished cleaning 0016 ---\n",
            "\n",
            "--- Processing video: 0015 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0015/annotation_cleaned.json'\n",
            "--- Finished cleaning 0015 ---\n",
            "\n",
            "--- Processing video: 0014 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0014/annotation_cleaned.json'\n",
            "--- Finished cleaning 0014 ---\n",
            "\n",
            "--- Processing video: 0013 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0013/annotation_cleaned.json'\n",
            "--- Finished cleaning 0013 ---\n",
            "\n",
            "--- Processing video: 0010 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0010/annotation_cleaned.json'\n",
            "--- Finished cleaning 0010 ---\n",
            "\n",
            "--- Processing video: 0008 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0008/annotation_cleaned.json'\n",
            "--- Finished cleaning 0008 ---\n",
            "\n",
            "--- Processing video: 0007 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0007/annotation_cleaned.json'\n",
            "--- Finished cleaning 0007 ---\n",
            "\n",
            "--- Processing video: 0004 ---\n",
            "  No non-allowed instruments found. Annotation file is already clean.\n",
            "  Saved cleaned annotations to 'dataset/0004/annotation_cleaned.json'\n",
            "--- Finished cleaning 0004 ---\n",
            "\n",
            "--- Processing video: 0002 ---\n",
            "  Removed 2 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0002/annotation_cleaned.json'\n",
            "--- Finished cleaning 0002 ---\n",
            "\n",
            "--- Processing video: 0052 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0052/annotation_cleaned.json'\n",
            "--- Finished cleaning 0052 ---\n",
            "\n",
            "--- Processing video: .ipynb_checkpoints ---\n",
            "  [Warning] 'annotation.json' not found for .ipynb_checkpoints. Skipping.\n",
            "--- Processing video: 0108 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0108/annotation_cleaned.json'\n",
            "--- Finished cleaning 0108 ---\n",
            "\n",
            "--- Processing video: 0027 ---\n",
            "  Removed 1 annotations for non-allowed instruments.\n",
            "  Saved cleaned annotations to 'dataset/0027/annotation_cleaned.json'\n",
            "--- Finished cleaning 0027 ---\n",
            "\n",
            "--- Processing video: 0009 ---\n",
            "  [Warning] 'annotation.json' not found for 0009. Skipping.\n",
            "🎉 All done!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ✏️ 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "# This should point to the folder containing your video subfolders.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# A list of video folder names to process.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\", \"0481\"]\n",
        "VIDEOS_TO_PROCESS = []  # <-- Leave empty to process all folders\n",
        "\n",
        "# A list of instrument class names that you want to KEEP.\n",
        "# \"Cannula\", \"Cap-Cystotome\", \"Cap-Forceps\", \"Cornea\", \"Forceps\",\n",
        "# \"IA-Handpiece\", \"Lens-Injector\", \"Phaco-Handpiece\", \"Primary-Knife\",\n",
        "# \"Pupil\", \"Second-Instrument\", \"Secondary-Knife\"\n",
        "# Example: ALLOWED_INSTRUMENTS = [\"Forceps\"]\n",
        "ALLOWED_INSTRUMENTS = [\"Forceps\", \"Cap-Cystotome\", \"Cap-Forceps\"]  # <-- CHANGE THIS\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ⚙️ 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# These classes are always preserved, regardless of the allowed instruments list.\n",
        "ALWAYS_KEPT_CLASSES = {\"Cornea\", \"Pupil\"}\n",
        "\n",
        "\n",
        "def clean_annotations(data, allowed_instruments):\n",
        "    \"\"\"\n",
        "    Filters the annotations list in the dataset based on a set of allowed classes.\n",
        "    \"\"\"\n",
        "    final_allowed_classes = set(allowed_instruments).union(ALWAYS_KEPT_CLASSES)\n",
        "    category_id_to_name = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    original_annotation_count = len(data['annotations'])\n",
        "    cleaned_annotations = []\n",
        "\n",
        "    for ann in data['annotations']:\n",
        "        category_id = ann['category_id']\n",
        "        class_name = category_id_to_name.get(category_id)\n",
        "        if class_name in final_allowed_classes:\n",
        "            cleaned_annotations.append(ann)\n",
        "\n",
        "    data['annotations'] = cleaned_annotations\n",
        "    removed_count = original_annotation_count - len(cleaned_annotations)\n",
        "    return data, removed_count\n",
        "\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "def run_cleaning():\n",
        "    \"\"\"\n",
        "    Parses arguments and runs the dataset cleaning process.\n",
        "    Saves the output as a new 'annotation_cleaned.json' file.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"❌ [Error] Dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        print(\"Please make sure the folder exists and you have uploaded your data.\")\n",
        "        return\n",
        "\n",
        "    # If no specific videos are listed, process all subdirectories\n",
        "    videos_to_process = VIDEOS_TO_PROCESS\n",
        "    if not videos_to_process:\n",
        "        videos_to_process = [name for name in os.listdir(DATASET_ROOT)\n",
        "                             if os.path.isdir(os.path.join(DATASET_ROOT, name))]\n",
        "        print(f\"📂 No videos specified. Automatically found {len(videos_to_process)} video(s) to process.\\n\")\n",
        "\n",
        "    allowed_instruments_set = set(ALLOWED_INSTRUMENTS)\n",
        "    print(f\"✅ Cleaning specified videos to only contain these instruments: {sorted(list(allowed_instruments_set))}\")\n",
        "    print(f\"(Note: '{', '.join(ALWAYS_KEPT_CLASSES)}' will always be kept)\\n\")\n",
        "\n",
        "    for video_name in videos_to_process:\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"--- Processing video: {video_name} ---\")\n",
        "\n",
        "        if not os.path.isdir(video_folder_path):\n",
        "            print(f\"  [Warning] Video folder not found: {video_folder_path}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        original_annotation_path = os.path.join(video_folder_path, \"annotation.json\")\n",
        "        cleaned_annotation_path = os.path.join(video_folder_path, \"annotation_cleaned.json\")\n",
        "\n",
        "        if not os.path.exists(original_annotation_path):\n",
        "            print(f\"  [Warning] 'annotation.json' not found for {video_name}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(original_annotation_path, 'r') as f:\n",
        "            data_to_clean = json.load(f)\n",
        "\n",
        "        cleaned_data, removed_count = clean_annotations(data_to_clean, allowed_instruments_set)\n",
        "\n",
        "        if removed_count > 0:\n",
        "            print(f\"  Removed {removed_count} annotations for non-allowed instruments.\")\n",
        "        else:\n",
        "            print(\"  No non-allowed instruments found. Annotation file is already clean.\")\n",
        "\n",
        "        with open(cleaned_annotation_path, 'w') as f:\n",
        "            json.dump(cleaned_data, f, indent=4)\n",
        "        print(f\"  Saved cleaned annotations to '{cleaned_annotation_path}'\")\n",
        "\n",
        "        print(f\"--- Finished cleaning {video_name} ---\\n\")\n",
        "\n",
        "    print(\"🎉 All done!\")\n",
        "\n",
        "\n",
        "# --- Run the script ---\n",
        "run_cleaning()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KT6epzKGdoE"
      },
      "source": [
        "## Handling Missing Labels\n",
        "This code cell handles missing labels in the dataset by using non-linear interpolation. It fills in the gaps in the annotations up to a specified maximum gap size. The interpolated annotations are saved to a new file named `annotation_miss_handled.json`.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `MAX_GAP_SIZE`: The maximum number of consecutive missing frames to interpolate.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `INPUT_ANNOTATION_FILENAME`: The filename of the input annotation file.\n",
        "- `OUTPUT_ANNOTATION_FILENAME`: The filename for the output annotation file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi65Yr8lFzFK",
        "outputId": "44dbd372-e636-4022-c406-9617cee3f00c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No specific video provided. Processing all videos in 'dataset/'...\n",
            "Found 175 video(s) to process: ['0001', '0002', '0003', '0004', '0005', '0006', '0007', '0008', '0010', '0011', '0012', '0013', '0014', '0015', '0016', '0017', '0018', '0019', '0020', '0021', '0022', '0023', '0024', '0025', '0026', '0027', '0028', '0029', '0030', '0031', '0032', '0033', '0034', '0035', '0036', '0037', '0038', '0039', '0040', '0041', '0042', '0043', '0044', '0045', '0046', '0047', '0048', '0049', '0050', '0051', '0052', '0053', '0054', '0055', '0056', '0057', '0058', '0059', '0060', '0061', '0062', '0063', '0064', '0065', '0066', '0068', '0073', '0082', '0099', '0101', '0107', '0108', '0118', '0125', '0134', '0139', '0151', '0154', '0168', '0181', '0185', '0190', '0192', '0202', '0204', '0208', '0209', '0211', '0220', '0221', '0222', '0223', '0233', '0289', '0295', '0303', '0313', '0314', '0320', '0321', '0326', '0327', '0328', '0329', '0330', '0331', '0332', '0338', '0342', '0343', '0344', '0346', '0349', '0351', '0353', '0355', '0365', '0369', '0377', '0378', '0380', '0382', '0384', '0386', '0390', '0393', '0394', '0396', '0398', '0399', '0401', '0404', '0407', '0408', '0410', '0411', '0412', '0413', '0416', '0419', '0420', '0423', '0425', '0426', '0429', '0437', '0438', '0439', '0453', '0470', '0472', '0474', '0476', '0481', '0495', '0505', '0533', '0534', '0538', '0549', '0560', '0598', '0605', '0610', '0640', '0642', '0669', '0674', '0711', '0713', '0716', '0721', '0724', '0747', '0780']\n",
            "\n",
            "--- Processing video: 0001 ---\n",
            "Total missing labels filled: 201\n",
            "  ✅ Saved new annotations to dataset/0001/annotation_miss_handled.json\n",
            "--- Finished processing 0001 ---\n",
            "\n",
            "--- Processing video: 0002 ---\n",
            "Total missing labels filled: 865\n",
            "  ✅ Saved new annotations to dataset/0002/annotation_miss_handled.json\n",
            "--- Finished processing 0002 ---\n",
            "\n",
            "--- Processing video: 0003 ---\n",
            "Total missing labels filled: 5\n",
            "  ✅ Saved new annotations to dataset/0003/annotation_miss_handled.json\n",
            "--- Finished processing 0003 ---\n",
            "\n",
            "--- Processing video: 0004 ---\n",
            "Total missing labels filled: 136\n",
            "  ✅ Saved new annotations to dataset/0004/annotation_miss_handled.json\n",
            "--- Finished processing 0004 ---\n",
            "\n",
            "--- Processing video: 0005 ---\n",
            "Total missing labels filled: 351\n",
            "  ✅ Saved new annotations to dataset/0005/annotation_miss_handled.json\n",
            "--- Finished processing 0005 ---\n",
            "\n",
            "--- Processing video: 0006 ---\n",
            "Total missing labels filled: 405\n",
            "  ✅ Saved new annotations to dataset/0006/annotation_miss_handled.json\n",
            "--- Finished processing 0006 ---\n",
            "\n",
            "--- Processing video: 0007 ---\n",
            "Total missing labels filled: 418\n",
            "  ✅ Saved new annotations to dataset/0007/annotation_miss_handled.json\n",
            "--- Finished processing 0007 ---\n",
            "\n",
            "--- Processing video: 0008 ---\n",
            "Total missing labels filled: 33\n",
            "  ✅ Saved new annotations to dataset/0008/annotation_miss_handled.json\n",
            "--- Finished processing 0008 ---\n",
            "\n",
            "--- Processing video: 0010 ---\n",
            "Total missing labels filled: 354\n",
            "  ✅ Saved new annotations to dataset/0010/annotation_miss_handled.json\n",
            "--- Finished processing 0010 ---\n",
            "\n",
            "--- Processing video: 0011 ---\n",
            "Total missing labels filled: 1318\n",
            "  ✅ Saved new annotations to dataset/0011/annotation_miss_handled.json\n",
            "--- Finished processing 0011 ---\n",
            "\n",
            "--- Processing video: 0012 ---\n",
            "Total missing labels filled: 779\n",
            "  ✅ Saved new annotations to dataset/0012/annotation_miss_handled.json\n",
            "--- Finished processing 0012 ---\n",
            "\n",
            "--- Processing video: 0013 ---\n",
            "Total missing labels filled: 162\n",
            "  ✅ Saved new annotations to dataset/0013/annotation_miss_handled.json\n",
            "--- Finished processing 0013 ---\n",
            "\n",
            "--- Processing video: 0014 ---\n",
            "Total missing labels filled: 565\n",
            "  ✅ Saved new annotations to dataset/0014/annotation_miss_handled.json\n",
            "--- Finished processing 0014 ---\n",
            "\n",
            "--- Processing video: 0015 ---\n",
            "Total missing labels filled: 322\n",
            "  ✅ Saved new annotations to dataset/0015/annotation_miss_handled.json\n",
            "--- Finished processing 0015 ---\n",
            "\n",
            "--- Processing video: 0016 ---\n",
            "Total missing labels filled: 224\n",
            "  ✅ Saved new annotations to dataset/0016/annotation_miss_handled.json\n",
            "--- Finished processing 0016 ---\n",
            "\n",
            "--- Processing video: 0017 ---\n",
            "Total missing labels filled: 616\n",
            "  ✅ Saved new annotations to dataset/0017/annotation_miss_handled.json\n",
            "--- Finished processing 0017 ---\n",
            "\n",
            "--- Processing video: 0018 ---\n",
            "Total missing labels filled: 24\n",
            "  ✅ Saved new annotations to dataset/0018/annotation_miss_handled.json\n",
            "--- Finished processing 0018 ---\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "Total missing labels filled: 469\n",
            "  ✅ Saved new annotations to dataset/0019/annotation_miss_handled.json\n",
            "--- Finished processing 0019 ---\n",
            "\n",
            "--- Processing video: 0020 ---\n",
            "Total missing labels filled: 62\n",
            "  ✅ Saved new annotations to dataset/0020/annotation_miss_handled.json\n",
            "--- Finished processing 0020 ---\n",
            "\n",
            "--- Processing video: 0021 ---\n",
            "Total missing labels filled: 20\n",
            "  ✅ Saved new annotations to dataset/0021/annotation_miss_handled.json\n",
            "--- Finished processing 0021 ---\n",
            "\n",
            "--- Processing video: 0022 ---\n",
            "Total missing labels filled: 89\n",
            "  ✅ Saved new annotations to dataset/0022/annotation_miss_handled.json\n",
            "--- Finished processing 0022 ---\n",
            "\n",
            "--- Processing video: 0023 ---\n",
            "Total missing labels filled: 563\n",
            "  ✅ Saved new annotations to dataset/0023/annotation_miss_handled.json\n",
            "--- Finished processing 0023 ---\n",
            "\n",
            "--- Processing video: 0024 ---\n",
            "Total missing labels filled: 119\n",
            "  ✅ Saved new annotations to dataset/0024/annotation_miss_handled.json\n",
            "--- Finished processing 0024 ---\n",
            "\n",
            "--- Processing video: 0025 ---\n",
            "Total missing labels filled: 46\n",
            "  ✅ Saved new annotations to dataset/0025/annotation_miss_handled.json\n",
            "--- Finished processing 0025 ---\n",
            "\n",
            "--- Processing video: 0026 ---\n",
            "Total missing labels filled: 185\n",
            "  ✅ Saved new annotations to dataset/0026/annotation_miss_handled.json\n",
            "--- Finished processing 0026 ---\n",
            "\n",
            "--- Processing video: 0027 ---\n",
            "Total missing labels filled: 492\n",
            "  ✅ Saved new annotations to dataset/0027/annotation_miss_handled.json\n",
            "--- Finished processing 0027 ---\n",
            "\n",
            "--- Processing video: 0028 ---\n",
            "Total missing labels filled: 126\n",
            "  ✅ Saved new annotations to dataset/0028/annotation_miss_handled.json\n",
            "--- Finished processing 0028 ---\n",
            "\n",
            "--- Processing video: 0029 ---\n",
            "Total missing labels filled: 236\n",
            "  ✅ Saved new annotations to dataset/0029/annotation_miss_handled.json\n",
            "--- Finished processing 0029 ---\n",
            "\n",
            "--- Processing video: 0030 ---\n",
            "Total missing labels filled: 199\n",
            "  ✅ Saved new annotations to dataset/0030/annotation_miss_handled.json\n",
            "--- Finished processing 0030 ---\n",
            "\n",
            "--- Processing video: 0031 ---\n",
            "Total missing labels filled: 48\n",
            "  ✅ Saved new annotations to dataset/0031/annotation_miss_handled.json\n",
            "--- Finished processing 0031 ---\n",
            "\n",
            "--- Processing video: 0032 ---\n",
            "Total missing labels filled: 5\n",
            "  ✅ Saved new annotations to dataset/0032/annotation_miss_handled.json\n",
            "--- Finished processing 0032 ---\n",
            "\n",
            "--- Processing video: 0033 ---\n",
            "Total missing labels filled: 16\n",
            "  ✅ Saved new annotations to dataset/0033/annotation_miss_handled.json\n",
            "--- Finished processing 0033 ---\n",
            "\n",
            "--- Processing video: 0034 ---\n",
            "Total missing labels filled: 223\n",
            "  ✅ Saved new annotations to dataset/0034/annotation_miss_handled.json\n",
            "--- Finished processing 0034 ---\n",
            "\n",
            "--- Processing video: 0035 ---\n",
            "Total missing labels filled: 245\n",
            "  ✅ Saved new annotations to dataset/0035/annotation_miss_handled.json\n",
            "--- Finished processing 0035 ---\n",
            "\n",
            "--- Processing video: 0036 ---\n",
            "Total missing labels filled: 163\n",
            "  ✅ Saved new annotations to dataset/0036/annotation_miss_handled.json\n",
            "--- Finished processing 0036 ---\n",
            "\n",
            "--- Processing video: 0037 ---\n",
            "Total missing labels filled: 1134\n",
            "  ✅ Saved new annotations to dataset/0037/annotation_miss_handled.json\n",
            "--- Finished processing 0037 ---\n",
            "\n",
            "--- Processing video: 0038 ---\n",
            "Total missing labels filled: 225\n",
            "  ✅ Saved new annotations to dataset/0038/annotation_miss_handled.json\n",
            "--- Finished processing 0038 ---\n",
            "\n",
            "--- Processing video: 0039 ---\n",
            "Total missing labels filled: 29\n",
            "  ✅ Saved new annotations to dataset/0039/annotation_miss_handled.json\n",
            "--- Finished processing 0039 ---\n",
            "\n",
            "--- Processing video: 0040 ---\n",
            "Total missing labels filled: 312\n",
            "  ✅ Saved new annotations to dataset/0040/annotation_miss_handled.json\n",
            "--- Finished processing 0040 ---\n",
            "\n",
            "--- Processing video: 0041 ---\n",
            "Total missing labels filled: 59\n",
            "  ✅ Saved new annotations to dataset/0041/annotation_miss_handled.json\n",
            "--- Finished processing 0041 ---\n",
            "\n",
            "--- Processing video: 0042 ---\n",
            "Total missing labels filled: 278\n",
            "  ✅ Saved new annotations to dataset/0042/annotation_miss_handled.json\n",
            "--- Finished processing 0042 ---\n",
            "\n",
            "--- Processing video: 0043 ---\n",
            "Total missing labels filled: 37\n",
            "  ✅ Saved new annotations to dataset/0043/annotation_miss_handled.json\n",
            "--- Finished processing 0043 ---\n",
            "\n",
            "--- Processing video: 0044 ---\n",
            "Total missing labels filled: 30\n",
            "  ✅ Saved new annotations to dataset/0044/annotation_miss_handled.json\n",
            "--- Finished processing 0044 ---\n",
            "\n",
            "--- Processing video: 0045 ---\n",
            "Total missing labels filled: 58\n",
            "  ✅ Saved new annotations to dataset/0045/annotation_miss_handled.json\n",
            "--- Finished processing 0045 ---\n",
            "\n",
            "--- Processing video: 0046 ---\n",
            "Total missing labels filled: 138\n",
            "  ✅ Saved new annotations to dataset/0046/annotation_miss_handled.json\n",
            "--- Finished processing 0046 ---\n",
            "\n",
            "--- Processing video: 0047 ---\n",
            "Total missing labels filled: 19\n",
            "  ✅ Saved new annotations to dataset/0047/annotation_miss_handled.json\n",
            "--- Finished processing 0047 ---\n",
            "\n",
            "--- Processing video: 0048 ---\n",
            "Total missing labels filled: 174\n",
            "  ✅ Saved new annotations to dataset/0048/annotation_miss_handled.json\n",
            "--- Finished processing 0048 ---\n",
            "\n",
            "--- Processing video: 0049 ---\n",
            "Total missing labels filled: 418\n",
            "  ✅ Saved new annotations to dataset/0049/annotation_miss_handled.json\n",
            "--- Finished processing 0049 ---\n",
            "\n",
            "--- Processing video: 0050 ---\n",
            "Total missing labels filled: 3\n",
            "  ✅ Saved new annotations to dataset/0050/annotation_miss_handled.json\n",
            "--- Finished processing 0050 ---\n",
            "\n",
            "--- Processing video: 0051 ---\n",
            "Total missing labels filled: 80\n",
            "  ✅ Saved new annotations to dataset/0051/annotation_miss_handled.json\n",
            "--- Finished processing 0051 ---\n",
            "\n",
            "--- Processing video: 0052 ---\n",
            "Total missing labels filled: 414\n",
            "  ✅ Saved new annotations to dataset/0052/annotation_miss_handled.json\n",
            "--- Finished processing 0052 ---\n",
            "\n",
            "--- Processing video: 0053 ---\n",
            "Total missing labels filled: 93\n",
            "  ✅ Saved new annotations to dataset/0053/annotation_miss_handled.json\n",
            "--- Finished processing 0053 ---\n",
            "\n",
            "--- Processing video: 0054 ---\n",
            "Total missing labels filled: 54\n",
            "  ✅ Saved new annotations to dataset/0054/annotation_miss_handled.json\n",
            "--- Finished processing 0054 ---\n",
            "\n",
            "--- Processing video: 0055 ---\n",
            "Total missing labels filled: 211\n",
            "  ✅ Saved new annotations to dataset/0055/annotation_miss_handled.json\n",
            "--- Finished processing 0055 ---\n",
            "\n",
            "--- Processing video: 0056 ---\n",
            "Total missing labels filled: 544\n",
            "  ✅ Saved new annotations to dataset/0056/annotation_miss_handled.json\n",
            "--- Finished processing 0056 ---\n",
            "\n",
            "--- Processing video: 0057 ---\n",
            "Total missing labels filled: 91\n",
            "  ✅ Saved new annotations to dataset/0057/annotation_miss_handled.json\n",
            "--- Finished processing 0057 ---\n",
            "\n",
            "--- Processing video: 0058 ---\n",
            "Total missing labels filled: 62\n",
            "  ✅ Saved new annotations to dataset/0058/annotation_miss_handled.json\n",
            "--- Finished processing 0058 ---\n",
            "\n",
            "--- Processing video: 0059 ---\n",
            "Total missing labels filled: 211\n",
            "  ✅ Saved new annotations to dataset/0059/annotation_miss_handled.json\n",
            "--- Finished processing 0059 ---\n",
            "\n",
            "--- Processing video: 0060 ---\n",
            "Total missing labels filled: 456\n",
            "  ✅ Saved new annotations to dataset/0060/annotation_miss_handled.json\n",
            "--- Finished processing 0060 ---\n",
            "\n",
            "--- Processing video: 0061 ---\n",
            "Total missing labels filled: 371\n",
            "  ✅ Saved new annotations to dataset/0061/annotation_miss_handled.json\n",
            "--- Finished processing 0061 ---\n",
            "\n",
            "--- Processing video: 0062 ---\n",
            "Total missing labels filled: 150\n",
            "  ✅ Saved new annotations to dataset/0062/annotation_miss_handled.json\n",
            "--- Finished processing 0062 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "Total missing labels filled: 478\n",
            "  ✅ Saved new annotations to dataset/0063/annotation_miss_handled.json\n",
            "--- Finished processing 0063 ---\n",
            "\n",
            "--- Processing video: 0064 ---\n",
            "Total missing labels filled: 341\n",
            "  ✅ Saved new annotations to dataset/0064/annotation_miss_handled.json\n",
            "--- Finished processing 0064 ---\n",
            "\n",
            "--- Processing video: 0065 ---\n",
            "Total missing labels filled: 716\n",
            "  ✅ Saved new annotations to dataset/0065/annotation_miss_handled.json\n",
            "--- Finished processing 0065 ---\n",
            "\n",
            "--- Processing video: 0066 ---\n",
            "Total missing labels filled: 53\n",
            "  ✅ Saved new annotations to dataset/0066/annotation_miss_handled.json\n",
            "--- Finished processing 0066 ---\n",
            "\n",
            "--- Processing video: 0068 ---\n",
            "Total missing labels filled: 431\n",
            "  ✅ Saved new annotations to dataset/0068/annotation_miss_handled.json\n",
            "--- Finished processing 0068 ---\n",
            "\n",
            "--- Processing video: 0073 ---\n",
            "Total missing labels filled: 32\n",
            "  ✅ Saved new annotations to dataset/0073/annotation_miss_handled.json\n",
            "--- Finished processing 0073 ---\n",
            "\n",
            "--- Processing video: 0082 ---\n",
            "Total missing labels filled: 581\n",
            "  ✅ Saved new annotations to dataset/0082/annotation_miss_handled.json\n",
            "--- Finished processing 0082 ---\n",
            "\n",
            "--- Processing video: 0099 ---\n",
            "Total missing labels filled: 148\n",
            "  ✅ Saved new annotations to dataset/0099/annotation_miss_handled.json\n",
            "--- Finished processing 0099 ---\n",
            "\n",
            "--- Processing video: 0101 ---\n",
            "Total missing labels filled: 319\n",
            "  ✅ Saved new annotations to dataset/0101/annotation_miss_handled.json\n",
            "--- Finished processing 0101 ---\n",
            "\n",
            "--- Processing video: 0107 ---\n",
            "Total missing labels filled: 495\n",
            "  ✅ Saved new annotations to dataset/0107/annotation_miss_handled.json\n",
            "--- Finished processing 0107 ---\n",
            "\n",
            "--- Processing video: 0108 ---\n",
            "Total missing labels filled: 125\n",
            "  ✅ Saved new annotations to dataset/0108/annotation_miss_handled.json\n",
            "--- Finished processing 0108 ---\n",
            "\n",
            "--- Processing video: 0118 ---\n",
            "Total missing labels filled: 19\n",
            "  ✅ Saved new annotations to dataset/0118/annotation_miss_handled.json\n",
            "--- Finished processing 0118 ---\n",
            "\n",
            "--- Processing video: 0125 ---\n",
            "Total missing labels filled: 258\n",
            "  ✅ Saved new annotations to dataset/0125/annotation_miss_handled.json\n",
            "--- Finished processing 0125 ---\n",
            "\n",
            "--- Processing video: 0134 ---\n",
            "Total missing labels filled: 192\n",
            "  ✅ Saved new annotations to dataset/0134/annotation_miss_handled.json\n",
            "--- Finished processing 0134 ---\n",
            "\n",
            "--- Processing video: 0139 ---\n",
            "Total missing labels filled: 228\n",
            "  ✅ Saved new annotations to dataset/0139/annotation_miss_handled.json\n",
            "--- Finished processing 0139 ---\n",
            "\n",
            "--- Processing video: 0151 ---\n",
            "Total missing labels filled: 129\n",
            "  ✅ Saved new annotations to dataset/0151/annotation_miss_handled.json\n",
            "--- Finished processing 0151 ---\n",
            "\n",
            "--- Processing video: 0154 ---\n",
            "Total missing labels filled: 187\n",
            "  ✅ Saved new annotations to dataset/0154/annotation_miss_handled.json\n",
            "--- Finished processing 0154 ---\n",
            "\n",
            "--- Processing video: 0168 ---\n",
            "Total missing labels filled: 189\n",
            "  ✅ Saved new annotations to dataset/0168/annotation_miss_handled.json\n",
            "--- Finished processing 0168 ---\n",
            "\n",
            "--- Processing video: 0181 ---\n",
            "Total missing labels filled: 292\n",
            "  ✅ Saved new annotations to dataset/0181/annotation_miss_handled.json\n",
            "--- Finished processing 0181 ---\n",
            "\n",
            "--- Processing video: 0185 ---\n",
            "Total missing labels filled: 564\n",
            "  ✅ Saved new annotations to dataset/0185/annotation_miss_handled.json\n",
            "--- Finished processing 0185 ---\n",
            "\n",
            "--- Processing video: 0190 ---\n",
            "Total missing labels filled: 69\n",
            "  ✅ Saved new annotations to dataset/0190/annotation_miss_handled.json\n",
            "--- Finished processing 0190 ---\n",
            "\n",
            "--- Processing video: 0192 ---\n",
            "Total missing labels filled: 567\n",
            "  ✅ Saved new annotations to dataset/0192/annotation_miss_handled.json\n",
            "--- Finished processing 0192 ---\n",
            "\n",
            "--- Processing video: 0202 ---\n",
            "Total missing labels filled: 466\n",
            "  ✅ Saved new annotations to dataset/0202/annotation_miss_handled.json\n",
            "--- Finished processing 0202 ---\n",
            "\n",
            "--- Processing video: 0204 ---\n",
            "Total missing labels filled: 3\n",
            "  ✅ Saved new annotations to dataset/0204/annotation_miss_handled.json\n",
            "--- Finished processing 0204 ---\n",
            "\n",
            "--- Processing video: 0208 ---\n",
            "Total missing labels filled: 55\n",
            "  ✅ Saved new annotations to dataset/0208/annotation_miss_handled.json\n",
            "--- Finished processing 0208 ---\n",
            "\n",
            "--- Processing video: 0209 ---\n",
            "Total missing labels filled: 11\n",
            "  ✅ Saved new annotations to dataset/0209/annotation_miss_handled.json\n",
            "--- Finished processing 0209 ---\n",
            "\n",
            "--- Processing video: 0211 ---\n",
            "Total missing labels filled: 3\n",
            "  ✅ Saved new annotations to dataset/0211/annotation_miss_handled.json\n",
            "--- Finished processing 0211 ---\n",
            "\n",
            "--- Processing video: 0220 ---\n",
            "Total missing labels filled: 85\n",
            "  ✅ Saved new annotations to dataset/0220/annotation_miss_handled.json\n",
            "--- Finished processing 0220 ---\n",
            "\n",
            "--- Processing video: 0221 ---\n",
            "Total missing labels filled: 145\n",
            "  ✅ Saved new annotations to dataset/0221/annotation_miss_handled.json\n",
            "--- Finished processing 0221 ---\n",
            "\n",
            "--- Processing video: 0222 ---\n",
            "Total missing labels filled: 51\n",
            "  ✅ Saved new annotations to dataset/0222/annotation_miss_handled.json\n",
            "--- Finished processing 0222 ---\n",
            "\n",
            "--- Processing video: 0223 ---\n",
            "Total missing labels filled: 235\n",
            "  ✅ Saved new annotations to dataset/0223/annotation_miss_handled.json\n",
            "--- Finished processing 0223 ---\n",
            "\n",
            "--- Processing video: 0233 ---\n",
            "Total missing labels filled: 10\n",
            "  ✅ Saved new annotations to dataset/0233/annotation_miss_handled.json\n",
            "--- Finished processing 0233 ---\n",
            "\n",
            "--- Processing video: 0289 ---\n",
            "Total missing labels filled: 36\n",
            "  ✅ Saved new annotations to dataset/0289/annotation_miss_handled.json\n",
            "--- Finished processing 0289 ---\n",
            "\n",
            "--- Processing video: 0295 ---\n",
            "Total missing labels filled: 32\n",
            "  ✅ Saved new annotations to dataset/0295/annotation_miss_handled.json\n",
            "--- Finished processing 0295 ---\n",
            "\n",
            "--- Processing video: 0303 ---\n",
            "Total missing labels filled: 167\n",
            "  ✅ Saved new annotations to dataset/0303/annotation_miss_handled.json\n",
            "--- Finished processing 0303 ---\n",
            "\n",
            "--- Processing video: 0313 ---\n",
            "Total missing labels filled: 199\n",
            "  ✅ Saved new annotations to dataset/0313/annotation_miss_handled.json\n",
            "--- Finished processing 0313 ---\n",
            "\n",
            "--- Processing video: 0314 ---\n",
            "Total missing labels filled: 30\n",
            "  ✅ Saved new annotations to dataset/0314/annotation_miss_handled.json\n",
            "--- Finished processing 0314 ---\n",
            "\n",
            "--- Processing video: 0320 ---\n",
            "Total missing labels filled: 38\n",
            "  ✅ Saved new annotations to dataset/0320/annotation_miss_handled.json\n",
            "--- Finished processing 0320 ---\n",
            "\n",
            "--- Processing video: 0321 ---\n",
            "Total missing labels filled: 248\n",
            "  ✅ Saved new annotations to dataset/0321/annotation_miss_handled.json\n",
            "--- Finished processing 0321 ---\n",
            "\n",
            "--- Processing video: 0326 ---\n",
            "Total missing labels filled: 446\n",
            "  ✅ Saved new annotations to dataset/0326/annotation_miss_handled.json\n",
            "--- Finished processing 0326 ---\n",
            "\n",
            "--- Processing video: 0327 ---\n",
            "Total missing labels filled: 32\n",
            "  ✅ Saved new annotations to dataset/0327/annotation_miss_handled.json\n",
            "--- Finished processing 0327 ---\n",
            "\n",
            "--- Processing video: 0328 ---\n",
            "Total missing labels filled: 278\n",
            "  ✅ Saved new annotations to dataset/0328/annotation_miss_handled.json\n",
            "--- Finished processing 0328 ---\n",
            "\n",
            "--- Processing video: 0329 ---\n",
            "Total missing labels filled: 127\n",
            "  ✅ Saved new annotations to dataset/0329/annotation_miss_handled.json\n",
            "--- Finished processing 0329 ---\n",
            "\n",
            "--- Processing video: 0330 ---\n",
            "Total missing labels filled: 206\n",
            "  ✅ Saved new annotations to dataset/0330/annotation_miss_handled.json\n",
            "--- Finished processing 0330 ---\n",
            "\n",
            "--- Processing video: 0331 ---\n",
            "Total missing labels filled: 73\n",
            "  ✅ Saved new annotations to dataset/0331/annotation_miss_handled.json\n",
            "--- Finished processing 0331 ---\n",
            "\n",
            "--- Processing video: 0332 ---\n",
            "Total missing labels filled: 54\n",
            "  ✅ Saved new annotations to dataset/0332/annotation_miss_handled.json\n",
            "--- Finished processing 0332 ---\n",
            "\n",
            "--- Processing video: 0338 ---\n",
            "Total missing labels filled: 45\n",
            "  ✅ Saved new annotations to dataset/0338/annotation_miss_handled.json\n",
            "--- Finished processing 0338 ---\n",
            "\n",
            "--- Processing video: 0342 ---\n",
            "Total missing labels filled: 99\n",
            "  ✅ Saved new annotations to dataset/0342/annotation_miss_handled.json\n",
            "--- Finished processing 0342 ---\n",
            "\n",
            "--- Processing video: 0343 ---\n",
            "Total missing labels filled: 83\n",
            "  ✅ Saved new annotations to dataset/0343/annotation_miss_handled.json\n",
            "--- Finished processing 0343 ---\n",
            "\n",
            "--- Processing video: 0344 ---\n",
            "Total missing labels filled: 89\n",
            "  ✅ Saved new annotations to dataset/0344/annotation_miss_handled.json\n",
            "--- Finished processing 0344 ---\n",
            "\n",
            "--- Processing video: 0346 ---\n",
            "Total missing labels filled: 63\n",
            "  ✅ Saved new annotations to dataset/0346/annotation_miss_handled.json\n",
            "--- Finished processing 0346 ---\n",
            "\n",
            "--- Processing video: 0349 ---\n",
            "Total missing labels filled: 18\n",
            "  ✅ Saved new annotations to dataset/0349/annotation_miss_handled.json\n",
            "--- Finished processing 0349 ---\n",
            "\n",
            "--- Processing video: 0351 ---\n",
            "Total missing labels filled: 0\n",
            "  ✅ Saved new annotations to dataset/0351/annotation_miss_handled.json\n",
            "--- Finished processing 0351 ---\n",
            "\n",
            "--- Processing video: 0353 ---\n",
            "Total missing labels filled: 53\n",
            "  ✅ Saved new annotations to dataset/0353/annotation_miss_handled.json\n",
            "--- Finished processing 0353 ---\n",
            "\n",
            "--- Processing video: 0355 ---\n",
            "Total missing labels filled: 43\n",
            "  ✅ Saved new annotations to dataset/0355/annotation_miss_handled.json\n",
            "--- Finished processing 0355 ---\n",
            "\n",
            "--- Processing video: 0365 ---\n",
            "Total missing labels filled: 203\n",
            "  ✅ Saved new annotations to dataset/0365/annotation_miss_handled.json\n",
            "--- Finished processing 0365 ---\n",
            "\n",
            "--- Processing video: 0369 ---\n",
            "Total missing labels filled: 93\n",
            "  ✅ Saved new annotations to dataset/0369/annotation_miss_handled.json\n",
            "--- Finished processing 0369 ---\n",
            "\n",
            "--- Processing video: 0377 ---\n",
            "Total missing labels filled: 556\n",
            "  ✅ Saved new annotations to dataset/0377/annotation_miss_handled.json\n",
            "--- Finished processing 0377 ---\n",
            "\n",
            "--- Processing video: 0378 ---\n",
            "Total missing labels filled: 161\n",
            "  ✅ Saved new annotations to dataset/0378/annotation_miss_handled.json\n",
            "--- Finished processing 0378 ---\n",
            "\n",
            "--- Processing video: 0380 ---\n",
            "Total missing labels filled: 281\n",
            "  ✅ Saved new annotations to dataset/0380/annotation_miss_handled.json\n",
            "--- Finished processing 0380 ---\n",
            "\n",
            "--- Processing video: 0382 ---\n",
            "Total missing labels filled: 1297\n",
            "  ✅ Saved new annotations to dataset/0382/annotation_miss_handled.json\n",
            "--- Finished processing 0382 ---\n",
            "\n",
            "--- Processing video: 0384 ---\n",
            "Total missing labels filled: 389\n",
            "  ✅ Saved new annotations to dataset/0384/annotation_miss_handled.json\n",
            "--- Finished processing 0384 ---\n",
            "\n",
            "--- Processing video: 0386 ---\n",
            "Total missing labels filled: 1047\n",
            "  ✅ Saved new annotations to dataset/0386/annotation_miss_handled.json\n",
            "--- Finished processing 0386 ---\n",
            "\n",
            "--- Processing video: 0390 ---\n",
            "Total missing labels filled: 614\n",
            "  ✅ Saved new annotations to dataset/0390/annotation_miss_handled.json\n",
            "--- Finished processing 0390 ---\n",
            "\n",
            "--- Processing video: 0393 ---\n",
            "Total missing labels filled: 279\n",
            "  ✅ Saved new annotations to dataset/0393/annotation_miss_handled.json\n",
            "--- Finished processing 0393 ---\n",
            "\n",
            "--- Processing video: 0394 ---\n",
            "Total missing labels filled: 118\n",
            "  ✅ Saved new annotations to dataset/0394/annotation_miss_handled.json\n",
            "--- Finished processing 0394 ---\n",
            "\n",
            "--- Processing video: 0396 ---\n",
            "Total missing labels filled: 1152\n",
            "  ✅ Saved new annotations to dataset/0396/annotation_miss_handled.json\n",
            "--- Finished processing 0396 ---\n",
            "\n",
            "--- Processing video: 0398 ---\n",
            "Total missing labels filled: 563\n",
            "  ✅ Saved new annotations to dataset/0398/annotation_miss_handled.json\n",
            "--- Finished processing 0398 ---\n",
            "\n",
            "--- Processing video: 0399 ---\n",
            "Total missing labels filled: 36\n",
            "  ✅ Saved new annotations to dataset/0399/annotation_miss_handled.json\n",
            "--- Finished processing 0399 ---\n",
            "\n",
            "--- Processing video: 0401 ---\n",
            "Total missing labels filled: 1\n",
            "  ✅ Saved new annotations to dataset/0401/annotation_miss_handled.json\n",
            "--- Finished processing 0401 ---\n",
            "\n",
            "--- Processing video: 0404 ---\n",
            "Total missing labels filled: 49\n",
            "  ✅ Saved new annotations to dataset/0404/annotation_miss_handled.json\n",
            "--- Finished processing 0404 ---\n",
            "\n",
            "--- Processing video: 0407 ---\n",
            "Total missing labels filled: 35\n",
            "  ✅ Saved new annotations to dataset/0407/annotation_miss_handled.json\n",
            "--- Finished processing 0407 ---\n",
            "\n",
            "--- Processing video: 0408 ---\n",
            "Total missing labels filled: 405\n",
            "  ✅ Saved new annotations to dataset/0408/annotation_miss_handled.json\n",
            "--- Finished processing 0408 ---\n",
            "\n",
            "--- Processing video: 0410 ---\n",
            "Total missing labels filled: 666\n",
            "  ✅ Saved new annotations to dataset/0410/annotation_miss_handled.json\n",
            "--- Finished processing 0410 ---\n",
            "\n",
            "--- Processing video: 0411 ---\n",
            "Total missing labels filled: 147\n",
            "  ✅ Saved new annotations to dataset/0411/annotation_miss_handled.json\n",
            "--- Finished processing 0411 ---\n",
            "\n",
            "--- Processing video: 0412 ---\n",
            "Total missing labels filled: 505\n",
            "  ✅ Saved new annotations to dataset/0412/annotation_miss_handled.json\n",
            "--- Finished processing 0412 ---\n",
            "\n",
            "--- Processing video: 0413 ---\n",
            "Total missing labels filled: 119\n",
            "  ✅ Saved new annotations to dataset/0413/annotation_miss_handled.json\n",
            "--- Finished processing 0413 ---\n",
            "\n",
            "--- Processing video: 0416 ---\n",
            "Total missing labels filled: 361\n",
            "  ✅ Saved new annotations to dataset/0416/annotation_miss_handled.json\n",
            "--- Finished processing 0416 ---\n",
            "\n",
            "--- Processing video: 0419 ---\n",
            "Total missing labels filled: 14\n",
            "  ✅ Saved new annotations to dataset/0419/annotation_miss_handled.json\n",
            "--- Finished processing 0419 ---\n",
            "\n",
            "--- Processing video: 0420 ---\n",
            "Total missing labels filled: 865\n",
            "  ✅ Saved new annotations to dataset/0420/annotation_miss_handled.json\n",
            "--- Finished processing 0420 ---\n",
            "\n",
            "--- Processing video: 0423 ---\n",
            "Total missing labels filled: 467\n",
            "  ✅ Saved new annotations to dataset/0423/annotation_miss_handled.json\n",
            "--- Finished processing 0423 ---\n",
            "\n",
            "--- Processing video: 0425 ---\n",
            "Total missing labels filled: 367\n",
            "  ✅ Saved new annotations to dataset/0425/annotation_miss_handled.json\n",
            "--- Finished processing 0425 ---\n",
            "\n",
            "--- Processing video: 0426 ---\n",
            "Total missing labels filled: 307\n",
            "  ✅ Saved new annotations to dataset/0426/annotation_miss_handled.json\n",
            "--- Finished processing 0426 ---\n",
            "\n",
            "--- Processing video: 0429 ---\n",
            "Total missing labels filled: 293\n",
            "  ✅ Saved new annotations to dataset/0429/annotation_miss_handled.json\n",
            "--- Finished processing 0429 ---\n",
            "\n",
            "--- Processing video: 0437 ---\n",
            "Total missing labels filled: 376\n",
            "  ✅ Saved new annotations to dataset/0437/annotation_miss_handled.json\n",
            "--- Finished processing 0437 ---\n",
            "\n",
            "--- Processing video: 0438 ---\n",
            "Total missing labels filled: 420\n",
            "  ✅ Saved new annotations to dataset/0438/annotation_miss_handled.json\n",
            "--- Finished processing 0438 ---\n",
            "\n",
            "--- Processing video: 0439 ---\n",
            "Total missing labels filled: 40\n",
            "  ✅ Saved new annotations to dataset/0439/annotation_miss_handled.json\n",
            "--- Finished processing 0439 ---\n",
            "\n",
            "--- Processing video: 0453 ---\n",
            "Total missing labels filled: 34\n",
            "  ✅ Saved new annotations to dataset/0453/annotation_miss_handled.json\n",
            "--- Finished processing 0453 ---\n",
            "\n",
            "--- Processing video: 0470 ---\n",
            "Total missing labels filled: 671\n",
            "  ✅ Saved new annotations to dataset/0470/annotation_miss_handled.json\n",
            "--- Finished processing 0470 ---\n",
            "\n",
            "--- Processing video: 0472 ---\n",
            "Total missing labels filled: 1255\n",
            "  ✅ Saved new annotations to dataset/0472/annotation_miss_handled.json\n",
            "--- Finished processing 0472 ---\n",
            "\n",
            "--- Processing video: 0474 ---\n",
            "Total missing labels filled: 474\n",
            "  ✅ Saved new annotations to dataset/0474/annotation_miss_handled.json\n",
            "--- Finished processing 0474 ---\n",
            "\n",
            "--- Processing video: 0476 ---\n",
            "Total missing labels filled: 1161\n",
            "  ✅ Saved new annotations to dataset/0476/annotation_miss_handled.json\n",
            "--- Finished processing 0476 ---\n",
            "\n",
            "--- Processing video: 0481 ---\n",
            "Total missing labels filled: 63\n",
            "  ✅ Saved new annotations to dataset/0481/annotation_miss_handled.json\n",
            "--- Finished processing 0481 ---\n",
            "\n",
            "--- Processing video: 0495 ---\n",
            "Total missing labels filled: 381\n",
            "  ✅ Saved new annotations to dataset/0495/annotation_miss_handled.json\n",
            "--- Finished processing 0495 ---\n",
            "\n",
            "--- Processing video: 0505 ---\n",
            "Total missing labels filled: 708\n",
            "  ✅ Saved new annotations to dataset/0505/annotation_miss_handled.json\n",
            "--- Finished processing 0505 ---\n",
            "\n",
            "--- Processing video: 0533 ---\n",
            "Total missing labels filled: 259\n",
            "  ✅ Saved new annotations to dataset/0533/annotation_miss_handled.json\n",
            "--- Finished processing 0533 ---\n",
            "\n",
            "--- Processing video: 0534 ---\n",
            "Total missing labels filled: 454\n",
            "  ✅ Saved new annotations to dataset/0534/annotation_miss_handled.json\n",
            "--- Finished processing 0534 ---\n",
            "\n",
            "--- Processing video: 0538 ---\n",
            "Total missing labels filled: 108\n",
            "  ✅ Saved new annotations to dataset/0538/annotation_miss_handled.json\n",
            "--- Finished processing 0538 ---\n",
            "\n",
            "--- Processing video: 0549 ---\n",
            "Total missing labels filled: 215\n",
            "  ✅ Saved new annotations to dataset/0549/annotation_miss_handled.json\n",
            "--- Finished processing 0549 ---\n",
            "\n",
            "--- Processing video: 0560 ---\n",
            "Total missing labels filled: 151\n",
            "  ✅ Saved new annotations to dataset/0560/annotation_miss_handled.json\n",
            "--- Finished processing 0560 ---\n",
            "\n",
            "--- Processing video: 0598 ---\n",
            "Total missing labels filled: 429\n",
            "  ✅ Saved new annotations to dataset/0598/annotation_miss_handled.json\n",
            "--- Finished processing 0598 ---\n",
            "\n",
            "--- Processing video: 0605 ---\n",
            "Total missing labels filled: 181\n",
            "  ✅ Saved new annotations to dataset/0605/annotation_miss_handled.json\n",
            "--- Finished processing 0605 ---\n",
            "\n",
            "--- Processing video: 0610 ---\n",
            "Total missing labels filled: 16\n",
            "  ✅ Saved new annotations to dataset/0610/annotation_miss_handled.json\n",
            "--- Finished processing 0610 ---\n",
            "\n",
            "--- Processing video: 0640 ---\n",
            "Total missing labels filled: 118\n",
            "  ✅ Saved new annotations to dataset/0640/annotation_miss_handled.json\n",
            "--- Finished processing 0640 ---\n",
            "\n",
            "--- Processing video: 0642 ---\n",
            "Total missing labels filled: 168\n",
            "  ✅ Saved new annotations to dataset/0642/annotation_miss_handled.json\n",
            "--- Finished processing 0642 ---\n",
            "\n",
            "--- Processing video: 0669 ---\n",
            "Total missing labels filled: 397\n",
            "  ✅ Saved new annotations to dataset/0669/annotation_miss_handled.json\n",
            "--- Finished processing 0669 ---\n",
            "\n",
            "--- Processing video: 0674 ---\n",
            "Total missing labels filled: 193\n",
            "  ✅ Saved new annotations to dataset/0674/annotation_miss_handled.json\n",
            "--- Finished processing 0674 ---\n",
            "\n",
            "--- Processing video: 0711 ---\n",
            "Total missing labels filled: 58\n",
            "  ✅ Saved new annotations to dataset/0711/annotation_miss_handled.json\n",
            "--- Finished processing 0711 ---\n",
            "\n",
            "--- Processing video: 0713 ---\n",
            "Total missing labels filled: 155\n",
            "  ✅ Saved new annotations to dataset/0713/annotation_miss_handled.json\n",
            "--- Finished processing 0713 ---\n",
            "\n",
            "--- Processing video: 0716 ---\n",
            "Total missing labels filled: 305\n",
            "  ✅ Saved new annotations to dataset/0716/annotation_miss_handled.json\n",
            "--- Finished processing 0716 ---\n",
            "\n",
            "--- Processing video: 0721 ---\n",
            "Total missing labels filled: 93\n",
            "  ✅ Saved new annotations to dataset/0721/annotation_miss_handled.json\n",
            "--- Finished processing 0721 ---\n",
            "\n",
            "--- Processing video: 0724 ---\n",
            "Total missing labels filled: 20\n",
            "  ✅ Saved new annotations to dataset/0724/annotation_miss_handled.json\n",
            "--- Finished processing 0724 ---\n",
            "\n",
            "--- Processing video: 0747 ---\n",
            "Total missing labels filled: 134\n",
            "  ✅ Saved new annotations to dataset/0747/annotation_miss_handled.json\n",
            "--- Finished processing 0747 ---\n",
            "\n",
            "--- Processing video: 0780 ---\n",
            "Total missing labels filled: 65\n",
            "  ✅ Saved new annotations to dataset/0780/annotation_miss_handled.json\n",
            "--- Finished processing 0780 ---\n",
            "\n",
            "🎉 All done!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "import math\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ✏️ 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# The maximum number of consecutive missing frames to interpolate.\n",
        "MAX_GAP_SIZE = 10\n",
        "\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE EMPTY (e.g., []) to process ALL video folders found in DATASET_ROOT.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\", \"0481\"]\n",
        "VIDEOS_TO_PROCESS = [] #<-- CHANGE THIS\n",
        "\n",
        "# The filename of the input annotation file (the one to read from).\n",
        "INPUT_ANNOTATION_FILENAME = \"annotation_cleaned.json\"\n",
        "\n",
        "# The filename for the output annotation file (the one that will be created).\n",
        "OUTPUT_ANNOTATION_FILENAME = \"annotation_miss_handled.json\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ⚙️ 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def ease_in_out_sine(t):\n",
        "    \"\"\"A non-linear easing function for smoother interpolation.\"\"\"\n",
        "    return -(math.cos(math.pi * t) - 1) / 2\n",
        "\n",
        "def interpolate_bbox(bbox_start, bbox_end, t):\n",
        "    \"\"\"Interpolates bounding box [x, y, w, h] using an easing function.\"\"\"\n",
        "    t_eased = ease_in_out_sine(t)\n",
        "    return [\n",
        "        int(bbox_start[0] * (1 - t_eased) + bbox_end[0] * t_eased),\n",
        "        int(bbox_start[1] * (1 - t_eased) + bbox_end[1] * t_eased),\n",
        "        int(bbox_start[2] * (1 - t_eased) + bbox_end[2] * t_eased),\n",
        "        int(bbox_start[3] * (1 - t_eased) + bbox_end[3] * t_eased),\n",
        "    ]\n",
        "\n",
        "def interpolate_keypoints(kp_start, kp_end, t):\n",
        "    \"\"\"Interpolates keypoints [x, y, v] using an easing function.\"\"\"\n",
        "    t_eased = ease_in_out_sine(t)\n",
        "    # Only interpolate if both points are visible (v=2)\n",
        "    if kp_start[2] == 2 and kp_end[2] == 2:\n",
        "        return [\n",
        "            int(kp_start[0] * (1 - t_eased) + kp_end[0] * t_eased),\n",
        "            int(kp_start[1] * (1 - t_eased) + kp_end[1] * t_eased),\n",
        "            2 # Mark as visible\n",
        "        ]\n",
        "    return [0, 0, 0] # Return non-visible if start or end is not visible\n",
        "\n",
        "def generate_interpolated_mask(seg_start, bbox_start, bbox_interpolated):\n",
        "    \"\"\"\n",
        "    Generates a new segmentation mask by resizing a template mask.\n",
        "    \"\"\"\n",
        "    if not seg_start or not seg_start[0]:\n",
        "        return None\n",
        "\n",
        "    x_s, y_s, w_s, h_s = bbox_start\n",
        "    if w_s <= 0 or h_s <= 0: return None\n",
        "\n",
        "    template_mask = np.zeros((h_s, w_s), dtype=np.uint8)\n",
        "    poly_start = np.array(seg_start[0], dtype=np.int32).reshape((-1, 1, 2))\n",
        "    poly_start[:, :, 0] -= x_s\n",
        "    poly_start[:, :, 1] -= y_s\n",
        "    cv2.fillPoly(template_mask, [poly_start], 255)\n",
        "\n",
        "    x_i, y_i, w_i, h_i = bbox_interpolated\n",
        "    if w_i <= 0 or h_i <= 0: return None\n",
        "\n",
        "    resized_mask = cv2.resize(template_mask, (w_i, h_i), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    contours, _ = cv2.findContours(resized_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours: return None\n",
        "\n",
        "    main_contour = contours[0]\n",
        "    main_contour[:, :, 0] += x_i\n",
        "    main_contour[:, :, 1] += y_i\n",
        "\n",
        "    return [main_contour.flatten().tolist()]\n",
        "\n",
        "\n",
        "# --- Main Processing Function ---\n",
        "\n",
        "def process_annotations(data, max_gap_size):\n",
        "    \"\"\"\n",
        "    Finds and fills missing label gaps in the annotation data.\n",
        "    \"\"\"\n",
        "    total_gaps_filled = 0\n",
        "    for ann in data['annotations']:\n",
        "        num_frames = len(ann['segmentations'])\n",
        "        idx = 0\n",
        "        while idx < num_frames:\n",
        "            # Find the start of a potential gap\n",
        "            if ann['segmentations'][idx] is None and idx > 0 and ann['segmentations'][idx-1] is not None:\n",
        "                start_gap_idx = idx\n",
        "\n",
        "                # Find the end of the gap\n",
        "                end_gap_idx = -1\n",
        "                for j in range(start_gap_idx, num_frames):\n",
        "                    if ann['segmentations'][j] is not None:\n",
        "                        end_gap_idx = j\n",
        "                        break\n",
        "\n",
        "                # If a valid gap is found within the threshold, process it\n",
        "                if end_gap_idx != -1:\n",
        "                    gap_size = end_gap_idx - start_gap_idx\n",
        "                    if 0 < gap_size <= max_gap_size:\n",
        "                        # print(f\"  Found gap of size {gap_size} for annotation ID {ann['id']} from frame {start_gap_idx} to {end_gap_idx-1}. Interpolating...\")\n",
        "                        total_gaps_filled += gap_size\n",
        "\n",
        "                        bbox_start = ann['bboxes'][start_gap_idx - 1]\n",
        "                        bbox_end = ann['bboxes'][end_gap_idx]\n",
        "                        seg_start = ann['segmentations'][start_gap_idx - 1]\n",
        "\n",
        "                        # Find category to determine keypoint stride\n",
        "                        category = next((cat for cat in data['categories'] if cat['id'] == ann['category_id']), None)\n",
        "                        if not category or 'keypoints' not in category: continue\n",
        "\n",
        "                        num_keypoints = len(category['keypoints'])\n",
        "                        kp_stride = num_keypoints * 3\n",
        "\n",
        "                        kp_list_start = ann['keypoints'][(start_gap_idx - 1) * kp_stride : start_gap_idx * kp_stride]\n",
        "                        kp_list_end = ann['keypoints'][end_gap_idx * kp_stride : (end_gap_idx + 1) * kp_stride]\n",
        "\n",
        "                        for i in range(gap_size):\n",
        "                            frame_idx = start_gap_idx + i\n",
        "                            t = (i + 1) / (gap_size + 1.0)\n",
        "\n",
        "                            inter_bbox = interpolate_bbox(bbox_start, bbox_end, t)\n",
        "                            ann['bboxes'][frame_idx] = inter_bbox\n",
        "\n",
        "                            inter_seg = generate_interpolated_mask(seg_start, bbox_start, inter_bbox)\n",
        "                            ann['segmentations'][frame_idx] = inter_seg\n",
        "\n",
        "                            if inter_seg and inter_seg[0]:\n",
        "                                contour = np.array(inter_seg[0]).reshape(-1, 2)\n",
        "                                ann['areas'][frame_idx] = int(cv2.contourArea(contour))\n",
        "                            else:\n",
        "                                ann['areas'][frame_idx] = 0\n",
        "\n",
        "                            inter_kp_list = []\n",
        "                            for kp_idx in range(num_keypoints):\n",
        "                                kp_start = kp_list_start[kp_idx*3 : (kp_idx+1)*3]\n",
        "                                kp_end = kp_list_end[kp_idx*3 : (kp_idx+1)*3]\n",
        "                                inter_kp = interpolate_keypoints(kp_start, kp_end, t)\n",
        "                                inter_kp_list.extend(inter_kp)\n",
        "\n",
        "                            start_kp_json_idx = frame_idx * kp_stride\n",
        "                            ann['keypoints'][start_kp_json_idx : start_kp_json_idx + kp_stride] = inter_kp_list\n",
        "\n",
        "                    idx = end_gap_idx\n",
        "                else:\n",
        "                    # No end to the gap was found, stop searching for this annotation\n",
        "                    idx = num_frames\n",
        "            else:\n",
        "                idx += 1\n",
        "\n",
        "    print(f\"Total missing labels filled: {total_gaps_filled}\")\n",
        "    return data\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ▶️ 3. EXECUTION\n",
        "#    This block runs the script using the configuration above.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def run_interpolation_script():\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"❌ [Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    # If no specific videos are listed, find all subdirectories in the dataset folder\n",
        "    if not VIDEOS_TO_PROCESS:\n",
        "        print(f\"No specific video provided. Processing all videos in '{DATASET_ROOT}'...\")\n",
        "        video_names = [os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)]\n",
        "    else:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"❌ No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_names)} video(s) to process: {sorted(video_names)}\")\n",
        "\n",
        "    for video_name in sorted(video_names):\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        # Define file paths\n",
        "        input_annotation_path = os.path.join(video_folder_path, INPUT_ANNOTATION_FILENAME)\n",
        "        output_annotation_path = os.path.join(video_folder_path, OUTPUT_ANNOTATION_FILENAME)\n",
        "\n",
        "        if not os.path.exists(input_annotation_path):\n",
        "            print(f\"  [Warning] Input file '{INPUT_ANNOTATION_FILENAME}' not found for {video_name}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(input_annotation_path, 'r') as f:\n",
        "            cleaned_data = json.load(f)\n",
        "\n",
        "        # Process the data to fill gaps\n",
        "        handled_data = process_annotations(cleaned_data, MAX_GAP_SIZE)\n",
        "\n",
        "        # Save the new annotation file\n",
        "        with open(output_annotation_path, 'w') as f:\n",
        "            json.dump(handled_data, f, indent=4)\n",
        "        print(f\"  ✅ Saved new annotations to {output_annotation_path}\")\n",
        "\n",
        "        print(f\"--- Finished processing {video_name} ---\")\n",
        "\n",
        "    print(\"\\n🎉 All done!\")\n",
        "\n",
        "# --- Run the script ---\n",
        "run_interpolation_script()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS6Aj8cLKHf2"
      },
      "source": [
        "## Outlier Removal\n",
        "This code cell removes outliers from the dataset. It uses a sliding window to detect outliers based on velocity and corrects them using Cubic Spline interpolation. The smoothed annotations are saved to a new file named `annotation_smooth.json`.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `WINDOW_SIZE`: The size of the sliding window used to check for local outliers.\n",
        "- `THRESHOLD_STD_DEV`: The number of standard deviations from the median velocity to consider a point an outlier.\n",
        "- `INSTRUMENT_CLASSES`: These classes are instruments whose trajectories will be smoothed.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `INPUT_ANNOTATION_FILENAME`: The filename of the input annotation file.\n",
        "- `OUTPUT_ANNOTATION_FILENAME`: The filename for the output annotation file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IuRnLgKH-dK",
        "outputId": "e4ecee68-3fe1-4f65-bef0-31df04d82072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos in 'dataset/'...\n",
            "Found 2 video(s) to process: ['0019', '0063']\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  Processing trajectory for 'Forceps' (ID: 0)...\n",
            "    -> Detected 269 outliers. Applying spline correction.\n",
            "  Processing trajectory for 'Cap-Cystotome' (ID: 1)...\n",
            "    -> Detected 243 outliers. Applying spline correction.\n",
            "  Processing trajectory for 'Cap-Forceps' (ID: 220)...\n",
            "  ✅ Saved smoothed annotations to dataset/0019/annotation_smooth.json\n",
            "--- Finished smoothing for 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  Processing trajectory for 'Cap-Cystotome' (ID: 0)...\n",
            "    -> Detected 469 outliers. Applying spline correction.\n",
            "  Processing trajectory for 'Forceps' (ID: 1)...\n",
            "    -> Detected 129 outliers. Applying spline correction.\n",
            "  ✅ Saved smoothed annotations to dataset/0063/annotation_smooth.json\n",
            "--- Finished smoothing for 0063 ---\n",
            "\n",
            "🎉 All done!\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from collections import deque\n",
        "from scipy.interpolate import CubicSpline\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ✏️ 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# --- Smoothing Parameters ---\n",
        "# The size of the sliding window used to check for local outliers.\n",
        "WINDOW_SIZE = 30 # since the frame rate of videos is 30fps\n",
        "# The number of standard deviations from the median velocity to consider a point an outlier.\n",
        "THRESHOLD_STD_DEV = 2.0\n",
        "# These classes are instruments whose trajectories will be smoothed.\n",
        "INSTRUMENT_CLASSES = {\n",
        "    \"Cannula\", \"Cap-Cystotome\", \"Cap-Forceps\", \"Forceps\", \"IA-Handpiece\",\n",
        "    \"Lens-Injector\", \"Phaco-Handpiece\", \"Primary-Knife\", \"Second-Instrument\",\n",
        "    \"Secondary-Knife\"\n",
        "}\n",
        "\n",
        "# --- Video & File Settings ---\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE EMPTY (e.g., []) to process ALL video folders found in DATASET_ROOT.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\", \"0481\"]\n",
        "VIDEOS_TO_PROCESS = [] #<-- CHANGE THIS\n",
        "\n",
        "# The filename of the input annotation file (the one to read from).\n",
        "INPUT_ANNOTATION_FILENAME = \"annotation_miss_handled.json\"\n",
        "\n",
        "# The filename for the output annotation file (the one that will be created).\n",
        "OUTPUT_ANNOTATION_FILENAME = \"annotation_smooth.json\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ⚙️ 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def smooth_trajectory_with_spline(keypoints, num_keypoints, window_size, threshold):\n",
        "    \"\"\"\n",
        "    Detects outliers in a trajectory based on velocity and corrects them\n",
        "    using Cubic Spline interpolation.\n",
        "    \"\"\"\n",
        "    # 1. Extract tip trajectory and calculate frame-to-frame velocities\n",
        "    # Assumes the 'tip' is the second keypoint in the list for a given frame.\n",
        "    tip_track, velocities = [], [0.0]\n",
        "    for i in range(0, len(keypoints), num_keypoints * 3):\n",
        "        # Tip is the second keypoint, its data starts at index 3\n",
        "        tip_data = keypoints[i+3 : i+6]\n",
        "        tip_track.append([tip_data[0], tip_data[1]] if tip_data[2] == 2 else None)\n",
        "\n",
        "    for i in range(1, len(tip_track)):\n",
        "        if tip_track[i] is not None and tip_track[i-1] is not None:\n",
        "            velocities.append(np.linalg.norm(np.array(tip_track[i]) - np.array(tip_track[i-1])))\n",
        "        else:\n",
        "            velocities.append(0.0)\n",
        "\n",
        "    # 2. Pass 1: Detect Outliers using a sliding window on velocity\n",
        "    outlier_indices = set()\n",
        "    window = deque(maxlen=window_size)\n",
        "    for i, velocity in enumerate(velocities):\n",
        "        window.append(velocity)\n",
        "        if len(window) < window_size // 2: continue\n",
        "\n",
        "        median_vel = np.median(window)\n",
        "        std_dev_vel = np.std(window)\n",
        "        # Set a minimum std deviation to handle flat-line velocity sections\n",
        "        if std_dev_vel < 1.0: std_dev_vel = 1.0\n",
        "\n",
        "        if velocity > median_vel + threshold * std_dev_vel:\n",
        "            outlier_indices.add(i)\n",
        "\n",
        "    if not outlier_indices:\n",
        "        return keypoints # No changes needed\n",
        "\n",
        "    print(f\"    -> Detected {len(outlier_indices)} outliers. Applying spline correction.\")\n",
        "\n",
        "    # 3. Pass 2: Correct Outliers with Cubic Spline Interpolation\n",
        "    good_indices, good_points = [], []\n",
        "    for i, point in enumerate(tip_track):\n",
        "        if i not in outlier_indices and point is not None:\n",
        "            good_indices.append(i)\n",
        "            good_points.append(point)\n",
        "\n",
        "    # A cubic spline needs at least 4 points for good results\n",
        "    if len(good_indices) < 4:\n",
        "        print(f\"    -> Warning: Not enough good points ({len(good_indices)}) for a reliable spline. Outliers will be removed (set to null).\")\n",
        "        for i in outlier_indices:\n",
        "            tip_track[i] = None\n",
        "    else:\n",
        "        # Create splines for x and y coordinates\n",
        "        spline_x = CubicSpline(good_indices, [p[0] for p in good_points])\n",
        "        spline_y = CubicSpline(good_indices, [p[1] for p in good_points])\n",
        "        # Use the splines to predict new positions for the outlier frames\n",
        "        for i in outlier_indices:\n",
        "            tip_track[i] = [spline_x(i), spline_y(i)]\n",
        "\n",
        "    # 4. Reconstruct the flat keypoints list with the corrected data\n",
        "    new_keypoints = list(keypoints)\n",
        "    for i, point in enumerate(tip_track):\n",
        "        idx = i * num_keypoints * 3\n",
        "        if point:\n",
        "            new_keypoints[idx + 3:idx + 6] = [int(point[0]), int(point[1]), 2]\n",
        "        else:\n",
        "            # If a point was an outlier and couldn't be interpolated, mark it as not visible\n",
        "            new_keypoints[idx + 3:idx + 6] = [0, 0, 0]\n",
        "\n",
        "    return new_keypoints\n",
        "\n",
        "def process_annotations(data, window_size, threshold):\n",
        "    \"\"\"\n",
        "    Main processing function that iterates through annotations and applies smoothing.\n",
        "    \"\"\"\n",
        "    category_map = {cat['id']: cat for cat in data['categories']}\n",
        "\n",
        "    for ann in data[\"annotations\"]:\n",
        "        class_name = category_map.get(ann['category_id'], {}).get('name')\n",
        "        if class_name in INSTRUMENT_CLASSES:\n",
        "            print(f\"  Processing trajectory for '{class_name}' (ID: {ann['id']})...\")\n",
        "            num_kps = len(category_map[ann['category_id']]['keypoints'])\n",
        "            # We need at least 2 keypoints (e.g., center and tip) to smooth the tip\n",
        "            if num_kps < 2:\n",
        "                print(f\"    -> Skipping, not enough keypoints ({num_kps}).\")\n",
        "                continue\n",
        "\n",
        "            ann['keypoints'] = smooth_trajectory_with_spline(\n",
        "                ann['keypoints'], num_kps, window_size, threshold\n",
        "            )\n",
        "    return data\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ▶️ 3. EXECUTION\n",
        "#    This block runs the script using the configuration above.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def run_smoothing_script():\n",
        "    \"\"\"\n",
        "    Finds annotation files and runs the trajectory smoothing process.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"❌ [Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    # If no specific videos are listed, find all subdirectories\n",
        "    if not VIDEOS_TO_PROCESS:\n",
        "        print(f\"No specific video provided. Processing all videos in '{DATASET_ROOT}'...\")\n",
        "        video_names = [os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)]\n",
        "    else:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"❌ No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_names)} video(s) to process: {sorted(video_names)}\")\n",
        "\n",
        "    for video_name in sorted(video_names):\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        # Define file paths\n",
        "        input_path = os.path.join(video_folder_path, INPUT_ANNOTATION_FILENAME)\n",
        "        output_path = os.path.join(video_folder_path, OUTPUT_ANNOTATION_FILENAME)\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"  [Warning] Input file '{INPUT_ANNOTATION_FILENAME}' not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(input_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Run the smoothing process\n",
        "        smoothed_data = process_annotations(data, WINDOW_SIZE, THRESHOLD_STD_DEV)\n",
        "\n",
        "        # Save the new annotation file\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(smoothed_data, f, indent=4)\n",
        "        print(f\"  ✅ Saved smoothed annotations to {output_path}\")\n",
        "\n",
        "        print(f\"--- Finished smoothing for {video_name} ---\")\n",
        "\n",
        "    print(\"\\n🎉 All done!\")\n",
        "\n",
        "# --- Run the script ---\n",
        "run_smoothing_script()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58KfPYygMBca"
      },
      "source": [
        "## Motion features\n",
        "This code cell adds motion features to the dataset. It calculates velocity, acceleration, and jerk for each instrument. It also calculates the relative position of the surgical instrument to the Pupil and the relative motion features. The enriched annotations are saved to a new file named `annotation_full.json`.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `INSTRUMENT_CLASSES`: These classes are instruments and will have motion features calculated.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `INPUT_ANNOTATION_FILENAME`: The filename of the input annotation file.\n",
        "- `OUTPUT_ANNOTATION_FILENAME`: The filename for the final output annotation file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtG65tjvK5iL",
        "outputId": "b5672829-7e6b-4e5e-b117-7de6cc6b19b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos in 'dataset/'...\n",
            "Found 2 video(s) to process: ['0019', '0063']\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  Calculating motion features for 'Forceps' (ID: 0).\n",
            "  Calculating motion features for 'Cap-Cystotome' (ID: 1).\n",
            "  Calculating motion features for 'Cap-Forceps' (ID: 220).\n",
            "  ✅ Saved final annotations with motion features to dataset/0019/annotation_full.json\n",
            "--- Finished processing 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  Calculating motion features for 'Cap-Cystotome' (ID: 0).\n",
            "  Calculating motion features for 'Forceps' (ID: 1).\n",
            "  ✅ Saved final annotations with motion features to dataset/0063/annotation_full.json\n",
            "--- Finished processing 0063 ---\n",
            "\n",
            "🎉 All done!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ✏️ 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# These classes are instruments and will have motion features calculated.\n",
        "INSTRUMENT_CLASSES = {\n",
        "    \"Cannula\", \"Cap-Cystotome\", \"Cap-Forceps\", \"Forceps\", \"IA-Handpiece\",\n",
        "    \"Lens-Injector\", \"Phaco-Handpiece\", \"Primary-Knife\", \"Second-Instrument\",\n",
        "    \"Secondary-Knife\"\n",
        "}\n",
        "\n",
        "# --- Video & File Settings ---\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE EMPTY (e.g., []) to process ALL video folders found in DATASET_ROOT.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\", \"0481\"]\n",
        "VIDEOS_TO_PROCESS = [] #<-- CHANGE THIS\n",
        "\n",
        "# The filename of the input annotation file (the one to read from).\n",
        "INPUT_ANNOTATION_FILENAME = \"annotation_smooth.json\"\n",
        "\n",
        "# The filename for the final output annotation file.\n",
        "OUTPUT_ANNOTATION_FILENAME = \"annotation_full.json\"\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ⚙️ 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def _calculate_kinematics(position_track):\n",
        "    \"\"\"\n",
        "    Calculates velocity, acceleration, and jerk from a trajectory of 2D points.\n",
        "    \"\"\"\n",
        "    num_frames = len(position_track)\n",
        "    velocities = [None] * num_frames\n",
        "    accelerations = [None] * num_frames\n",
        "    jerks = [None] * num_frames\n",
        "\n",
        "    # Calculate Velocities (pixels/frame)\n",
        "    for i in range(1, num_frames):\n",
        "        p1 = position_track[i-1]\n",
        "        p2 = position_track[i]\n",
        "        if p1 is not None and p2 is not None:\n",
        "            velocities[i] = [p2[0] - p1[0], p2[1] - p1[1]]\n",
        "\n",
        "    # Calculate Accelerations (pixels/frame^2)\n",
        "    for i in range(1, num_frames):\n",
        "        v1 = velocities[i-1]\n",
        "        v2 = velocities[i]\n",
        "        if v1 is not None and v2 is not None:\n",
        "            accelerations[i] = [v2[0] - v1[0], v2[1] - v1[1]]\n",
        "\n",
        "    # Calculate Jerks (pixels/frame^3)\n",
        "    for i in range(1, num_frames):\n",
        "        a1 = accelerations[i-1]\n",
        "        a2 = accelerations[i]\n",
        "        if a1 is not None and a2 is not None:\n",
        "            jerks[i] = [a2[0] - a1[0], a2[1] - a1[1]]\n",
        "\n",
        "    return velocities, accelerations, jerks\n",
        "\n",
        "def process_video_annotations(data):\n",
        "    \"\"\"\n",
        "    Adds motion features to all instrument annotations in the dataset.\n",
        "    \"\"\"\n",
        "    category_map = {cat['id']: cat for cat in data['categories']}\n",
        "    if not data.get('videos') or not data['videos'][0].get('file_names'):\n",
        "        print(\"  [Error] 'videos' or 'file_names' not found in JSON. Cannot determine frame count.\")\n",
        "        return None\n",
        "    num_frames = len(data['videos'][0]['file_names'])\n",
        "\n",
        "    # 1. Find the Pupil's center trajectory first. This is our reference.\n",
        "    pupil_center_track = [None] * num_frames\n",
        "    pupil_ann = next((ann for ann in data['annotations'] if category_map.get(ann['category_id'], {}).get('name') == \"Pupil\"), None)\n",
        "\n",
        "    if pupil_ann:\n",
        "        num_keypoints = len(category_map[pupil_ann['category_id']]['keypoints'])\n",
        "        for i in range(num_frames):\n",
        "            kp_base_idx = i * num_keypoints * 3\n",
        "            # Center is the first keypoint\n",
        "            center_data = pupil_ann['keypoints'][kp_base_idx : kp_base_idx + 3]\n",
        "            if center_data[2] == 2: # If center is visible\n",
        "                pupil_center_track[i] = [center_data[0], center_data[1]]\n",
        "    else:\n",
        "        print(\"  [Warning] Pupil annotation not found. Relative kinematics will not be calculated.\")\n",
        "\n",
        "    # 2. Iterate through annotations and process instruments\n",
        "    for ann in data['annotations']:\n",
        "        class_name = category_map.get(ann['category_id'], {}).get('name')\n",
        "\n",
        "        if class_name in INSTRUMENT_CLASSES:\n",
        "            print(f\"  Calculating motion features for '{class_name}' (ID: {ann['id']}).\")\n",
        "            num_keypoints = len(category_map[ann['category_id']]['keypoints'])\n",
        "            if num_keypoints < 2:\n",
        "                print(f\"    -> Skipping, instrument requires at least 2 keypoints but has {num_keypoints}.\")\n",
        "                continue\n",
        "\n",
        "            # a. Extract the instrument's absolute tip trajectory\n",
        "            tip_track_abs = [None] * num_frames\n",
        "            for i in range(num_frames):\n",
        "                kp_base_idx = i * num_keypoints * 3\n",
        "                # Tip is the second keypoint\n",
        "                tip_data = ann['keypoints'][kp_base_idx + 3 : kp_base_idx + 6]\n",
        "                if tip_data[2] == 2: # If tip is visible\n",
        "                    tip_track_abs[i] = [tip_data[0], tip_data[1]]\n",
        "\n",
        "            # b. Calculate absolute kinematics\n",
        "            vel_abs, acc_abs, jerk_abs = _calculate_kinematics(tip_track_abs)\n",
        "\n",
        "            # c. Calculate the relative position trajectory\n",
        "            tip_track_rel = [None] * num_frames\n",
        "            for i in range(num_frames):\n",
        "                if tip_track_abs[i] is not None and pupil_center_track[i] is not None:\n",
        "                    tip_track_rel[i] = [\n",
        "                        tip_track_abs[i][0] - pupil_center_track[i][0],\n",
        "                        tip_track_abs[i][1] - pupil_center_track[i][1]\n",
        "                    ]\n",
        "\n",
        "            # d. Calculate relative kinematics\n",
        "            vel_rel, acc_rel, jerk_rel = _calculate_kinematics(tip_track_rel)\n",
        "\n",
        "            # e. Add the new \"motion_features\" object to the annotation\n",
        "            ann['motion_features'] = {\n",
        "                \"absolute\": {\n",
        "                    \"velocity\": vel_abs,\n",
        "                    \"acceleration\": acc_abs,\n",
        "                    \"jerk\": jerk_abs\n",
        "                },\n",
        "                \"relative_to_pupil\": {\n",
        "                    \"position\": tip_track_rel,\n",
        "                    \"velocity\": vel_rel,\n",
        "                    \"acceleration\": acc_rel,\n",
        "                    \"jerk\": jerk_rel\n",
        "                }\n",
        "            }\n",
        "\n",
        "    return data\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ▶️ 3. EXECUTION\n",
        "#    This block runs the script using the configuration above.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def run_feature_calculation():\n",
        "    \"\"\"\n",
        "    Finds annotation files and runs the motion feature calculation process.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"❌ [Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    # If no specific videos are listed, find all subdirectories\n",
        "    if not VIDEOS_TO_PROCESS:\n",
        "        print(f\"No specific video provided. Processing all videos in '{DATASET_ROOT}'...\")\n",
        "        video_names = [os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)]\n",
        "    else:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"❌ No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_names)} video(s) to process: {sorted(video_names)}\")\n",
        "\n",
        "    # --- Processing Loop ---\n",
        "    for video_name in sorted(video_names):\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        # Define file paths\n",
        "        input_path = os.path.join(video_folder_path, INPUT_ANNOTATION_FILENAME)\n",
        "        output_path = os.path.join(video_folder_path, OUTPUT_ANNOTATION_FILENAME)\n",
        "\n",
        "        if not os.path.exists(input_path):\n",
        "            print(f\"  [Warning] Input file '{INPUT_ANNOTATION_FILENAME}' not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(input_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Process the data to add motion features\n",
        "        enriched_data = process_video_annotations(data)\n",
        "\n",
        "        if enriched_data:\n",
        "            # Save the new, fully-featured annotation file\n",
        "            with open(output_path, 'w') as f:\n",
        "                json.dump(enriched_data, f, indent=4)\n",
        "            print(f\"  ✅ Saved final annotations with motion features to {output_path}\")\n",
        "        else:\n",
        "            print(f\"  [Error] Processing failed for video {video_name}. Output file not saved.\")\n",
        "\n",
        "        print(f\"--- Finished processing {video_name} ---\")\n",
        "\n",
        "    print(\"\\n🎉 All done!\")\n",
        "\n",
        "\n",
        "# --- Run the script ---\n",
        "run_feature_calculation()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwOM-eVjPKfm"
      },
      "source": [
        "## Visualize motion features and trajectories\n",
        "This code cell visualizes the motion features and trajectories. It generates and saves a grid of plots for each specified instrument. The plots include the absolute and relative trajectories, as well as the absolute and relative velocity, acceleration, and jerk.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset to visualize.\n",
        "- `VISUALIZATION_OUTPUT_DIR`: The directory where the output plot images will be saved.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `INSTRUMENTS_TO_PLOT`: A list of specific instrument names to plot. Leave empty to plot all instruments.\n",
        "- `COMPARE_WITH_CLEANED`: Set to True to overlay the original trajectory from \"annotation_cleaned.json\" for comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDplTIMtMjlr",
        "outputId": "8347480f-266f-4fe6-a558-bc1b8b39ee1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos...\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  -> Loading 'annotation_cleaned.json' for comparison.\n",
            "  -> Generating plots for 'Forceps' (ID: 0)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n",
            "     Saved plot to visualizations/0019_Forceps_motion_analysis.png\n",
            "  -> Generating plots for 'Cap-Cystotome' (ID: 1)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n",
            "     Saved plot to visualizations/0019_Cap-Cystotome_motion_analysis.png\n",
            "  -> Generating plots for 'Cap-Forceps' (ID: 220)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-20-2637010369.py:58: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  ax.legend()\n",
            "/tmp/ipython-input-20-2637010369.py:107: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "  abs_ax.legend()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Saved plot to visualizations/0019_Cap-Forceps_motion_analysis.png\n",
            "--- Finished plotting for 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  -> Loading 'annotation_cleaned.json' for comparison.\n",
            "  -> Generating plots for 'Cap-Cystotome' (ID: 0)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n",
            "     Saved plot to visualizations/0063_Cap-Cystotome_motion_analysis.png\n",
            "  -> Generating plots for 'Forceps' (ID: 1)...\n",
            "     Found corresponding 'cleaned' annotation for comparison.\n",
            "     Saved plot to visualizations/0063_Forceps_motion_analysis.png\n",
            "--- Finished plotting for 0063 ---\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==================================\n",
        "# === 📝 GLOBAL CONFIGURATION 📝 ===\n",
        "# ==================================\n",
        "# The root directory of the dataset to visualize.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# The directory where the output plot images will be saved.\n",
        "VISUALIZATION_OUTPUT_DIR = \"visualizations/\"\n",
        "\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE THIS LIST EMPTY (e.g., []) to process ALL videos.\n",
        "VIDEOS_TO_PROCESS = []\n",
        "\n",
        "# A list of specific instrument names to plot.\n",
        "# LEAVE THIS LIST EMPTY (e.g., []) to plot ALL instruments.\n",
        "INSTRUMENTS_TO_PLOT = []\n",
        "\n",
        "# Set to True to overlay the original trajectory from \"annotation_cleaned.json\"\n",
        "# for comparison. Set to False to only plot the final trajectory.\n",
        "COMPARE_WITH_CLEANED = True\n",
        "\n",
        "\n",
        "# --- Helper Functions ---\n",
        "\n",
        "def calculate_magnitude(vectors):\n",
        "    \"\"\"Calculates the magnitude of a list of 2D vectors.\"\"\"\n",
        "    magnitudes = [np.linalg.norm(v) if v is not None and len(v) == 2 else np.nan for v in vectors]\n",
        "    return magnitudes\n",
        "\n",
        "def plot_kinematics(ax, data, title, color):\n",
        "    \"\"\"Plots a single kinematic feature (magnitude vs. time).\"\"\"\n",
        "    ax.plot(data, label=title, color=color, linewidth=1.5)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Frame Number\")\n",
        "    ax.set_ylabel(\"Magnitude (pixels/frame^n)\")\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    ax.legend()\n",
        "    ax.margins(x=0.01)\n",
        "\n",
        "def plot_trajectory(ax, trajectory, title, color, alpha=1.0):\n",
        "    \"\"\"Plots a 2D trajectory (Y vs. X).\"\"\"\n",
        "    valid_points = np.array([p for p in trajectory if p is not None])\n",
        "    if valid_points.size > 0:\n",
        "        ax.plot(valid_points[:, 0], valid_points[:, 1], 'o-', label=title, color=color, markersize=2, linewidth=1, alpha=alpha)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"X Coordinate\")\n",
        "    ax.set_ylabel(\"Y Coordinate\")\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "    if \"Absolute\" in title:\n",
        "        ax.invert_yaxis()\n",
        "    ax.grid(True, linestyle='--', alpha=0.6)\n",
        "    ax.legend()\n",
        "\n",
        "# --- Main Processing Function ---\n",
        "\n",
        "def generate_plots_for_video(data, video_name, instruments_to_plot, cleaned_data=None):\n",
        "    \"\"\"Generates and saves a grid of plots for each specified instrument.\"\"\"\n",
        "    category_map = {cat['id']: cat for cat in data['categories']}\n",
        "    cleaned_category_map = {cat['id']: cat for cat in cleaned_data['categories']} if cleaned_data else None\n",
        "\n",
        "    for ann in data['annotations']:\n",
        "        category_id = ann['category_id']\n",
        "        class_name = category_map.get(category_id, {}).get('name')\n",
        "\n",
        "        if not class_name or class_name not in instruments_to_plot:\n",
        "            continue\n",
        "\n",
        "        if 'motion_features' not in ann:\n",
        "            print(f\"  -> Skipping '{class_name}': No 'motion_features' found.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"  -> Generating plots for '{class_name}' (ID: {ann['id']})...\")\n",
        "\n",
        "        features = ann['motion_features']\n",
        "\n",
        "        # Extract the smoothed absolute trajectory\n",
        "        num_keypoints = len(category_map[category_id]['keypoints'])\n",
        "        kp_stride = num_keypoints * 3\n",
        "        absolute_trajectory = [[ann['keypoints'][i+3], ann['keypoints'][i+4]] if ann['keypoints'][i+5] == 2 else None for i in range(0, len(ann['keypoints']), kp_stride)]\n",
        "\n",
        "        # Find and extract the original trajectory for comparison\n",
        "        original_absolute_trajectory = None\n",
        "        if cleaned_data:\n",
        "            original_ann = next((o_ann for o_ann in cleaned_data['annotations'] if cleaned_category_map.get(o_ann['category_id'], {}).get('name') == class_name), None)\n",
        "            if original_ann:\n",
        "                print(f\"     Found corresponding 'cleaned' annotation for comparison.\")\n",
        "                o_num_keypoints = len(cleaned_category_map[original_ann['category_id']]['keypoints'])\n",
        "                o_kp_stride = o_num_keypoints * 3\n",
        "                original_absolute_trajectory = [[original_ann['keypoints'][i+3], original_ann['keypoints'][i+4]] if original_ann['keypoints'][i+5] == 2 else None for i in range(0, len(original_ann['keypoints']), o_kp_stride)]\n",
        "\n",
        "        # --- Create a 4x2 plot grid ---\n",
        "        fig, axes = plt.subplots(4, 2, figsize=(18, 24))\n",
        "        fig.suptitle(f\"Motion Analysis for '{class_name}'\\nVideo: {video_name}\", fontsize=20, y=0.96)\n",
        "\n",
        "        # Plotting\n",
        "        abs_ax = axes[0, 0]\n",
        "        plot_trajectory(abs_ax, absolute_trajectory, 'Smoothed Trajectory', 'royalblue')\n",
        "        if original_absolute_trajectory:\n",
        "            plot_trajectory(abs_ax, original_absolute_trajectory, 'Original (Cleaned)', 'red', alpha=0.7)\n",
        "        abs_ax.set_title(\"Absolute Trajectory Comparison\")\n",
        "        abs_ax.legend()\n",
        "\n",
        "        plot_trajectory(axes[0, 1], features['relative_to_pupil']['position'], 'Relative Trajectory (to Pupil)', 'seagreen')\n",
        "        plot_kinematics(axes[1, 0], calculate_magnitude(features['absolute']['velocity']), 'Absolute Velocity', 'royalblue')\n",
        "        plot_kinematics(axes[1, 1], calculate_magnitude(features['relative_to_pupil']['velocity']), 'Relative Velocity', 'seagreen')\n",
        "        plot_kinematics(axes[2, 0], calculate_magnitude(features['absolute']['acceleration']), 'Absolute Acceleration', 'royalblue')\n",
        "        plot_kinematics(axes[2, 1], calculate_magnitude(features['relative_to_pupil']['acceleration']), 'Relative Acceleration', 'seagreen')\n",
        "        plot_kinematics(axes[3, 0], calculate_magnitude(features['absolute']['jerk']), 'Absolute Jerk', 'royalblue')\n",
        "        plot_kinematics(axes[3, 1], calculate_magnitude(features['relative_to_pupil']['jerk']), 'Relative Jerk', 'seagreen')\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "\n",
        "        # Save the figure\n",
        "        output_filename = os.path.join(VISUALIZATION_OUTPUT_DIR, f\"{video_name}_{class_name}_motion_analysis.png\")\n",
        "        plt.savefig(output_filename, bbox_inches='tight')\n",
        "        print(f\"     Saved plot to {output_filename}\")\n",
        "        plt.close(fig)\n",
        "\n",
        "# --- Main Execution Block ---\n",
        "\n",
        "def main():\n",
        "    os.makedirs(VISUALIZATION_OUTPUT_DIR, exist_ok=True)\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"[Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    # Determine which videos to process\n",
        "    if VIDEOS_TO_PROCESS:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "    else:\n",
        "        print(\"No specific video provided. Processing all videos...\")\n",
        "        video_names = sorted([os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)])\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    for video_name in video_names:\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        full_path = os.path.join(video_folder_path, \"annotation_full.json\")\n",
        "        if not os.path.exists(full_path):\n",
        "            print(f\"  [Warning] Input file 'annotation_full.json' not found. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        with open(full_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        cleaned_data_for_comparison = None\n",
        "        if COMPARE_WITH_CLEANED:\n",
        "            cleaned_path = os.path.join(video_folder_path, \"annotation_cleaned.json\")\n",
        "            if os.path.exists(cleaned_path):\n",
        "                print(f\"  -> Loading 'annotation_cleaned.json' for comparison.\")\n",
        "                with open(cleaned_path, 'r') as f:\n",
        "                    cleaned_data_for_comparison = json.load(f)\n",
        "            else:\n",
        "                print(f\"  [Warning] Comparison file 'annotation_cleaned.json' not found. Comparison skipped.\")\n",
        "\n",
        "        # Determine which instruments to plot\n",
        "        all_instrument_names = {cat['name'] for cat in data['categories'] if cat['name'] not in {'Pupil', 'Cornea'}}\n",
        "        if INSTRUMENTS_TO_PLOT:\n",
        "            instruments_to_plot = set(INSTRUMENTS_TO_PLOT)\n",
        "        else:\n",
        "            instruments_to_plot = all_instrument_names\n",
        "\n",
        "        generate_plots_for_video(data, video_name, instruments_to_plot, cleaned_data=cleaned_data_for_comparison)\n",
        "\n",
        "        print(f\"--- Finished plotting for {video_name} ---\")\n",
        "\n",
        "# --- Run the script ---\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m42Tg3YFQQAu"
      },
      "source": [
        "## Video Visualization\n",
        "This code cell creates annotated videos from the dataset. It draws the annotations on each frame of the video and saves the annotated video to a new file.\n",
        "\n",
        "### Configurations:\n",
        "- `DATASET_ROOT`: The root directory of the dataset.\n",
        "- `VIDEO_OUTPUT_DIR`: The directory where the output annotated videos will be saved.\n",
        "- `INPUT_ANNOTATION_FILENAME`: The exact name of the annotation file to use for visualization.\n",
        "- `VIDEOS_TO_PROCESS`: A list of specific video folder names to process. Leave empty to process all videos.\n",
        "- `COLOR_DICT`: A dictionary of colors to use for the different classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmthFEbDQTnp",
        "outputId": "cc9da998-0141-4628-e739-b08de58fe11f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No specific video provided. Processing all videos...\n",
            "Found 2 video(s) to process: ['0019', '0063']\n",
            "\n",
            "--- Processing video: 0019 ---\n",
            "  -> Loading annotations from: annotation_full.json\n",
            "  -> Creating video: 0019_from_annotation_full.mp4\n",
            "    Processing frame 3276/3276\n",
            "  -> ✅ Successfully created video: visualized_videos_motion/0019_from_annotation_full.mp4\n",
            "--- Finished video creation for 0019 ---\n",
            "\n",
            "--- Processing video: 0063 ---\n",
            "  -> Loading annotations from: annotation_full.json\n",
            "  -> Creating video: 0063_from_annotation_full.mp4\n",
            "    Processing frame 5799/5799\n",
            "  -> ✅ Successfully created video: visualized_videos_motion/0063_from_annotation_full.mp4\n",
            "--- Finished video creation for 0063 ---\n",
            "\n",
            "🎉 All done!\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ✏️ 1. CONFIGURATION\n",
        "#    Modify the variables in this section to match your needs.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "# Path to the root directory of the dataset.\n",
        "DATASET_ROOT = \"dataset/\"\n",
        "\n",
        "# Directory where the output annotated videos will be saved.\n",
        "VIDEO_OUTPUT_DIR = \"visualized_videos_motion/\"\n",
        "\n",
        "# The exact name of the annotation file to use for visualization.\n",
        "# This file must exist in each video folder you process.\n",
        "# Examples: \"annotation.json\", \"annotation_cleaned.json\", \"annotation_full.json\"\n",
        "INPUT_ANNOTATION_FILENAME = \"annotation_full.json\" #<-- CHANGE THIS\n",
        "\n",
        "# A list of specific video folder names to process.\n",
        "# LEAVE EMPTY (e.g., []) to process ALL video folders found in DATASET_ROOT.\n",
        "# Example: VIDEOS_TO_PROCESS = [\"0020\"]\n",
        "VIDEOS_TO_PROCESS = [] #<-- CHANGE THIS\n",
        "\n",
        "# Define a color dictionary for consistent class colors\n",
        "COLOR_DICT = {\n",
        "    \"Cannula\": (255, 0, 0), \"Cap-Cystotome\": (0, 255, 0), \"Cap-Forceps\": (0, 0, 255),\n",
        "    \"Cornea\": (255, 255, 0), \"Forceps\": (255, 0, 255), \"IA-Handpiece\": (0, 255, 255),\n",
        "    \"Lens-Injector\": (125, 125, 0), \"Phaco-Handpiece\": (0, 125, 125), \"Primary-Knife\": (125, 0, 125),\n",
        "    \"Pupil\": (50, 200, 200), \"Second-Instrument\": (200, 200, 50), \"Secondary-Knife\": (200, 50, 200),\n",
        "    \"Default\": (128, 128, 128)\n",
        "}\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ⚙️ 2. CORE LOGIC\n",
        "#    You don't need to change the code below this line.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def draw_annotations_on_frame(frame, annotations_for_frame):\n",
        "    \"\"\"Draws all annotations for a single frame.\"\"\"\n",
        "    overlay = frame.copy()\n",
        "\n",
        "    for ann in annotations_for_frame:\n",
        "        class_name = ann['class_name']\n",
        "        color = COLOR_DICT.get(class_name, COLOR_DICT[\"Default\"])\n",
        "\n",
        "        # Draw segmentation mask with transparency\n",
        "        if ann['segmentation']:\n",
        "            poly = np.array(ann['segmentation'][0], dtype=np.int32).reshape((-1, 1, 2))\n",
        "            cv2.fillPoly(overlay, [poly], color)\n",
        "\n",
        "        # Draw bounding box\n",
        "        if ann['bbox']:\n",
        "            x, y, w, h = [int(v) for v in ann['bbox']]\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "            # Draw class label\n",
        "            label = f\"{class_name}\"\n",
        "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
        "\n",
        "        # Draw keypoints (assumes max 2 keypoints: center and tip)\n",
        "        if ann['keypoints']:\n",
        "            # Center (first keypoint)\n",
        "            if ann['keypoints'][2] == 2:\n",
        "                center_x, center_y = int(ann['keypoints'][0]), int(ann['keypoints'][1])\n",
        "                cv2.circle(frame, (center_x, center_y), 6, (255, 0, 0), -1, cv2.LINE_AA) # Blue center\n",
        "            # Tip (second keypoint, if it exists)\n",
        "            if len(ann['keypoints']) > 5 and ann['keypoints'][5] == 2:\n",
        "                tip_x, tip_y = int(ann['keypoints'][3]), int(ann['keypoints'][4])\n",
        "                cv2.circle(frame, (tip_x, tip_y), 6, (0, 0, 255), -1, cv2.LINE_AA) # Red tip\n",
        "\n",
        "    # Apply the overlay with transparency\n",
        "    cv2.addWeighted(overlay, 0.4, frame, 0.6, 0, frame)\n",
        "    return frame\n",
        "\n",
        "def create_video(video_folder_path, json_filename):\n",
        "    \"\"\"Creates an annotated video from a folder of frames and a JSON file.\"\"\"\n",
        "    video_name = os.path.basename(video_folder_path)\n",
        "    input_json_path = os.path.join(video_folder_path, json_filename)\n",
        "\n",
        "    if not os.path.exists(input_json_path):\n",
        "        print(f\"  [Error] Annotation file not found: {input_json_path}. Skipping video creation.\")\n",
        "        return\n",
        "\n",
        "    print(f\"  -> Loading annotations from: {json_filename}\")\n",
        "    with open(input_json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    category_map = {cat['id']: cat['name'] for cat in data['categories']}\n",
        "    cat_id_to_num_kps = {cat['id']: len(cat.get('keypoints', [])) for cat in data['categories']}\n",
        "\n",
        "    num_frames = len(data['videos'][0]['file_names'])\n",
        "    all_frames_data = [[] for _ in range(num_frames)]\n",
        "\n",
        "    for ann in data['annotations']:\n",
        "        class_name = category_map.get(ann['category_id'], \"Unknown\")\n",
        "        num_keypoints = cat_id_to_num_kps.get(ann['category_id'], 0)\n",
        "        kp_stride = num_keypoints * 3\n",
        "\n",
        "        for i in range(num_frames):\n",
        "            # Check if the annotation exists for this frame\n",
        "            if ann.get('segmentations') and i < len(ann['segmentations']) and ann['segmentations'][i]:\n",
        "                frame_ann = {\n",
        "                    'class_name': class_name,\n",
        "                    'segmentation': ann['segmentations'][i],\n",
        "                    'bbox': ann['bboxes'][i] if ann.get('bboxes') and i < len(ann['bboxes']) else None,\n",
        "                    'keypoints': ann['keypoints'][i * kp_stride : (i + 1) * kp_stride] if ann.get('keypoints') and kp_stride > 0 else []\n",
        "                }\n",
        "                all_frames_data[i].append(frame_ann)\n",
        "\n",
        "    # --- Video Creation ---\n",
        "    output_video_name = f\"{video_name}_from_{os.path.splitext(json_filename)[0]}.mp4\"\n",
        "    output_video_path = os.path.join(VIDEO_OUTPUT_DIR, output_video_name)\n",
        "\n",
        "    width = data['videos'][0]['width']\n",
        "    height = data['videos'][0]['height']\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out_writer = cv2.VideoWriter(output_video_path, fourcc, 30.0, (width, height))\n",
        "\n",
        "    print(f\"  -> Creating video: {output_video_name}\")\n",
        "    for i, frame_filename in enumerate(data['videos'][0]['file_names']):\n",
        "        frame_path = os.path.join(video_folder_path, frame_filename)\n",
        "        if not os.path.exists(frame_path):\n",
        "            print(f\"\\n    [Warning] Frame not found: {frame_path}. Using a black frame instead.\")\n",
        "            frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            frame = cv2.imread(frame_path)\n",
        "\n",
        "        annotated_frame = draw_annotations_on_frame(frame, all_frames_data[i])\n",
        "\n",
        "        out_writer.write(annotated_frame)\n",
        "        print(f\"    Processing frame {i+1}/{num_frames}\", end='\\r')\n",
        "\n",
        "    out_writer.release()\n",
        "    print(f\"\\n  -> ✅ Successfully created video: {output_video_path}\")\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------\n",
        "# ▶️ 3. EXECUTION\n",
        "#    This block runs the script using the configuration above.\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def run_video_creation_script():\n",
        "    \"\"\"Finds videos and their annotation files to generate annotated videos.\"\"\"\n",
        "    os.makedirs(VIDEO_OUTPUT_DIR, exist_ok=True)\n",
        "    if not os.path.exists(DATASET_ROOT):\n",
        "        print(f\"❌ [Error] Input dataset directory not found at '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    if not VIDEOS_TO_PROCESS:\n",
        "        print(\"No specific video provided. Processing all videos...\")\n",
        "        video_names = [os.path.basename(d) for d in glob.glob(os.path.join(DATASET_ROOT, '*')) if os.path.isdir(d)]\n",
        "    else:\n",
        "        video_names = VIDEOS_TO_PROCESS\n",
        "\n",
        "    if not video_names:\n",
        "        print(f\"❌ No video subdirectories found in '{DATASET_ROOT}'\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(video_names)} video(s) to process: {sorted(video_names)}\")\n",
        "\n",
        "    for video_name in sorted(video_names):\n",
        "        video_folder_path = os.path.join(DATASET_ROOT, video_name)\n",
        "        print(f\"\\n--- Processing video: {video_name} ---\")\n",
        "\n",
        "        create_video(video_folder_path, INPUT_ANNOTATION_FILENAME)\n",
        "\n",
        "        print(f\"--- Finished video creation for {video_name} ---\")\n",
        "\n",
        "    print(\"\\n🎉 All done!\")\n",
        "\n",
        "# --- Run the script ---\n",
        "run_video_creation_script()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}